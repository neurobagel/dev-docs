{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to the Neurobagel developer docs","text":"<p>This is where we keep documentation to help the development team keep building and maintaining Neurobagel.</p> <p>If you would like to learn more about Neurobagel and how to use it, please visit the Neurobagel website.</p> <p>Note</p> <p>We're currently moving our docs from HackMD to this site. Please check back soon.</p>"},{"location":"backend/API/","title":"API","text":"","tags":["Internal Documentation"]},{"location":"backend/API/#notes-on-cors","title":"Notes on CORS","text":"<p>Without CORS enabled, you can indeed not send a query from the query tool to the API in any (of the tested) settings. That is because the query tool and the API run on different Origins even locally. All as documented. </p> <p>The next question is what we should do about this and what the risks are. My understanding of the former is that the safest bet in this order would be: - don't allow CORS - allow CORS only for a-priori trusted origins - allow CORS but don't return <code>*</code> in the CORS request response headers. </p> <p>My understanding of the latter part isn't as clear yet, but essentially it seems to be that the risk is \"not very big\" for our current public API, but \"potentially severe\" for internal APIs. The risk is that a trusted origin (query.neurobagel.org) loads some script from an untrusted place (evil.org) and that script now does silly things against our API and is then allowed to read the results. Because our API is meant to be queried by anyone, I think the consequences of this happening would be very limited to none. For an internal API this is obviously very different, because that API expects to only be talked to from inside the network and so an attacking script could gain access to information it is not allowed to see. </p> <p>Because we want to build things with the most constrained use case in mind, my conclusion is that CORS has to go in the way we use it now (which to be fair was mostly for prototyping anyway). Now we've also come to like functional web tools, so we'll have to find a solution for how the query tool and the API can still work together. There are a couple.</p> <p>For a public deployment (like ours on query.neurobagel.org), we have two choices I can see: 1. explicitly only allow the trusted origin (query.neurobagel.org) 2. host the API and the query tool from the same origin. This would mean that   - we host both by ourselves from our server (no more GH pages for the query tool)   - we change their URLs to be routes on the same domain (e.g. neurobagel.org/api and neurobagel.org/query)   - we configure nginx to route these internally to the correct ports</p> <p>For now I vote for option 1 because it is less involved and still quite reasonable. But we could go to 2. directly.</p> <p>For an internal deployment (whether dev or intranet) to have the same outcome, we need to instead allow the localhost port the query tool is running on. So we should explicitly allow localhost:3000 if the query tool is hosted on :3000. This needs to be transparently configurable by the user for obvious reasons. It's of course also possible to configure nginx locally to avoid CORS alltogether, but I think that's a pretty high bar for a first deployment - particularly because we don't ship a configured nginx with our stuff.</p> <p>Oh and although we don't have this yet (but definitely want to): for e2e tests during the CI, we would likely use the same setup as for an internal deployment and expect it to work.</p> <p>Additional notes: - none of this will affect direct (e.g. via curl) requests to the API - they will still work - out of curiosity I'd be interested if <code>allow CORS but don't return</code>*<code>in the header</code> and how that could be achieved</p>","tags":["Internal Documentation"]},{"location":"backend/API/#neurobagel-hosted-apis","title":"Neurobagel-hosted APIs","text":"<p>Server name: <code>fairmount</code> IP: 206.12.99.17</p> API/graph database name graph backend port URL open_neuro GraphDB 8000 https://api.neurobagel.org federation N/A 8080 https://federate.neurobagel.org indi GraphDB 8001 https://indi.neurobagel.org <p>Server name: <code>st-viateur</code> IP: 206.12.89.194</p> <p>API/graph database name | graph backend | port ---- | ---- | ---- | mni_ppmi | GraphDB | 8888 mni_qpn | GraphDB | 8080</p>","tags":["Internal Documentation"]},{"location":"backend/BIC%20node%20federation/","title":"BIC internal node federation","text":"<p>Below are some problems uniquely encountered on the <code>neurobagel-node</code> VM.</p> <p>(See also Docker)</p>","tags":["Deployment"]},{"location":"backend/BIC%20node%20federation/#hostdockerinternal","title":"<code>host.docker.internal</code>","text":"<ul> <li>The f-API (in either a standalone container on the default bridge network, or our <code>local_federation recipe</code>) cannot access services on <code>host.docker.internal</code></li> <li>Seemingly, only using the external URL for the n-API (NGINX) in <code>local_nb_nodes.json</code> works</li> <li><code>host.docker.internal</code> successfully resolves to whatever the bridge network IP address is, but services with published ports on the host still can't be reached</li> </ul>","tags":["Deployment"]},{"location":"backend/BIC%20node%20federation/#reaching-vm-from-inside-container-on-vm","title":"Reaching VM from inside container on VM","text":"<ul> <li>from inside the <code>neurobagel-node</code> VM we can connect to a n-API running on the same machine using the public URL of the n-API (https://api-bic.neurobagel.org)</li> <li>however: if a request is made from inside a docker container on this machine using the public IP or hostname of the machine, it fails</li> <li><code>ping</code> works, but <code>curl</code> fails, indicating a firewall/port issue</li> <li>this problem only arose after access to the node became restricted using iptables</li> </ul> <p>Our temporary solution (just for this machine): - We manually add the f-API container to same network as the n-API+graph - We update <code>local_nb_nodes.json</code> on <code>neurobagel-node</code> to use the container name of n-API as the <code>ApiURL</code> for the federation index rather than its public URL</p> <p>Here are the commands we use for that:</p> <p><pre><code># docker network connect &lt;n-API-network&gt; &lt;f-API-container&gt;\ndocker network connect bic_pd_node_nodenet bic_federation-federation-1\n</code></pre> Note: this command needs to be rerun whenever the f-API Compose stack (i.e., the f-API container) has been stopped and restarted.</p> <p>and long term: - we want to switch to using one Compose network for all services so that all requests come from inside network</p>","tags":["Deployment"]},{"location":"backend/Keycloak/","title":"Keycloak","text":""},{"location":"backend/Keycloak/#keycloak","title":"Keycloak","text":""},{"location":"backend/Keycloak/#terminology","title":"Terminology","text":"<ul> <li>\"Realm\": a set of users, credentials, roles, groups that are managed in independently</li> <li>each user belongs to &amp; logs into a realm</li> <li>there's a \"Master\" realm, which is not recommended for apps<ul> <li>only for managing other realms</li> </ul> </li> <li>apps are secured under a specific realm</li> </ul>"},{"location":"backend/Keycloak/#features","title":"Features","text":"<ul> <li>supports out-of-the-box IdPs incl. Google, GitHub, LinkedIn, etc.</li> <li>also flexible enough to support integration of any OIDC or SAML 2.0 provider</li> <li>After a Keycloak realm has been created, Google can be added as an identity provider (using the Google API client ID &amp; secret)</li> <li>A user can then log in to the Keycloak conigured client with Google (as well as a standard login)</li> <li>You can also create a client in Keycloak directly (and not use an IdP), under a specific realm (which you have manually created users for ?)</li> </ul>"},{"location":"backend/Keycloak/#steps-to-automate","title":"Steps to automate","text":"<p>From the command line (as part of our deploy recipe?): - create a new realm &amp; configure the IdP for the realm (add credentials for a Google App)     - Each node controls their own Keycloak instance - Create a client for the ~~query tool~~ node API - Create custom client roles (maybe two to start)     1. Send query + view aggregated results         - should be the default if user has authenticated     3. Send query + view non-aggregated results - enable token exchange</p>"},{"location":"backend/Keycloak/#possible-workflow","title":"Possible workflow","text":"<p>Query Tool (Client in Keycloak):</p> <ul> <li>User logs in using Google through Keycloak</li> <li>Query tool obtains an access token for the user</li> </ul> <p>Federation API (Service):   - Query tool sends the user's access token to the Federation API.   - Federation API performs a token exchange using the access token to get a new token for the node API client.   - Federation API forwards the new token to the node API</p> <p>Node API (Client in Keycloak): - Node API verifies the token received from the Federation API. - Node API uses the verified token to identify the user and perform role-based access control. - Admin can then view users who have logged in using the admin console and assign more roles</p> <p>Resources: https://www.keycloak.org/docs/latest/server_admin/#assigning-permissions-using-roles-and-groups</p>"},{"location":"backend/Keycloak/#keycloak-token-exchange","title":"Keycloak token exchange","text":"<ul> <li>Client can:</li> <li>exchange existing Keycloak token for one client for token targeted for another client<ul> <li>does this work across realms?</li> </ul> </li> <li>exchange Keycloak token for token stored for a linked social provider acct (?)</li> <li>exchange external token from another Keycloak realm to internal token</li> <li>Token exchange is a client endpoint</li> </ul>"},{"location":"backend/Keycloak/#qs","title":"Q's","text":"<ul> <li>Should f-API (initiating token exchange) talk to the n-API Keycloak or the query tool Keycloak for the exchange process??</li> </ul>"},{"location":"backend/Keycloak/#docker","title":"Docker","text":"<ul> <li>keycloak has a docker image to get us started: https://www.keycloak.org/getting-started/getting-started-docker</li> <li>They offer docs on customizing and optimizing the container: https://www.keycloak.org/server/containers</li> </ul>"},{"location":"backend/Keycloak/#backend","title":"Backend","text":"<ul> <li>They offer docs on how to \"secure an application\": https://www.keycloak.org/docs/latest/securing_apps/index.html#planning-for-securing-applications-and-services</li> <li>The docs mention multiple grant types or as we're familiar with them oauth flows e.g., authorization code, implicit, etc</li> <li>The docs don't mention a Python adaptor for OIDC but found: https://github.com/marcospereirampj/python-keycloak/tree/master</li> </ul> <p>Resources: - https://medium.com/keycloak/github-as-identity-provider-in-keyclaok-dca95a9d80ca - https://keycloakthemes.com/blog/how-to-setup-sign-in-with-google-using-keycloak - https://medium.com/@stefannovak96/signing-in-with-google-with-keycloak-bf5166e93d1e</p>"},{"location":"backend/Keycloak/#keycloak-in-react","title":"Keycloak in React","text":"<ul> <li>https://walkingtreetech.medium.com/a-detailed-guide-to-securing-react-applications-with-keycloak-9434a95b4f4f</li> <li>https://medium.com/@aalam-info-solutions-llp/how-to-providing-keycloak-authentication-for-react-application-27cab703a386</li> </ul>"},{"location":"backend/OAuth%20_%20OIDC%20dump/","title":"OAuth / OIDC dump","text":""},{"location":"backend/OAuth%20_%20OIDC%20dump/#seb-brain-dump","title":"Seb brain dump","text":"<ul> <li>OAuth is a protocol that allows a user to give an app (A) specific (scoped) access to data in an app (B) without revealing credentials<ul> <li>classic example: budget app (A) wants to see your transaction in your bank (B). Historically (and still today) this (insanely) involves(d) sharing your actual username and password with app (A)</li> <li>OAuth removes the need to share credentials</li> </ul> </li> <li>OAuth bottom line is:<ul> <li>give access to a resource</li> </ul> </li> <li>OIDC is a layer on top of OAuth<ul> <li>because OAuth works so well and identity for things like SSO were hard before</li> <li>OIDC is mainly used so app A can let you log in with e.g. github and then show your beautiful profile picture and some other basic info about you as a user</li> <li>so the \"resource\" OIDC accesses is your identity</li> </ul> </li> <li>There are different OIDC flows (implicit, some other thing)<ul> <li>A lot of the security relies on the fact that an app that wants to use OIDC with a specific identity provider (e.g. github) first has to register with the identity provider</li> <li>that means, my app goes to github, says \"hello, it's me, the app, here is my public key. when I call back later to ask about Sebs account, this will prove it's really me asking\"</li> <li>When Seb logs into the identity provider (IP) there is a specific prompt \"Do you want to give app A access to the following scopes?\" (e.g. email, name, avatar ...). If Seb says yes, there is a redirect URL that includes a special code.</li> <li>The App can now parse the code from the redirect URL and then go to the IP and say: \"Hey, Seb just said I could look at his avatar and email. Here is a code to prove that. Can I please get an identity token in exchange\". And then the IP gives the token back which includes a bunch of other things, but mainly says \"Yes, I, the Identity Provider, confirm that this is really Seb you just talked to\"</li> <li>Finally, the App can exchange the identity token for more detailed user info about Seb at a identity resource API from the identity provider</li> </ul> </li> </ul> <p>Final thing: - because identity tokens are issued by the IP on behalf of a user, for the consumption of a specific app, things (may) get tricky when we introduce our federated network.  - Because the app in our case would be e.g. the query tool, but each node in the network would have to validate the identity token it receives with the federated query.  - So probably we will have to look into something called Token Exchange (https://oauth.net/2/token-exchange/). - I don't get that whole thing fully yet - but my understanding is that Neurobagel would get the initial OIDC token, and would then exchange the token for a new token for each node in the network.  - So from the perspective of a Neurobagel node that receives a federated query, the identity token would be asserted by Neurobagel, and not by the identity provider.  - If that is the case (e.g. Neurobagel would have to be an intermediary identity provider) that would not be great. Ideally we can find a way how a user goes through one OIDC flow and then each node can validate the token</p> <p>Take a look at some of the resources I found useful. Most useful probably is the GitHub OIDC flow tutorial. I think the tutorial is not in python, but should be reasonably easy to translate.</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#2024-07-02","title":"2024-07-02","text":"<p>Implementation thoughts: - Step 1: OIDC workflow should run in the frontend     - Should make GH user icon appear in top right corner of query tool (showing context from the OAuth) - How does query tool talk to federation API differently after logging into GH?   - Auth scoped to specific application   - Query tools becomes a registered OAuth app on GH   - What do we do w/ identity token   - Step 2: As part of request to f-API, JWT is set to f-API, which then double checks w/ GH        - f-API then sends that over to n-API, which does the GH check again   - issue: every jump needs a token   - needs to check at every step = zero trust       - otherwise, everyone needs to essentially trust the f-API instead of a third party app (e.g., GitHub) - this is called token exchange - f-API needs to validate who is sending request - feature flag for dev.</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#resources","title":"Resources","text":"<ul> <li>https://www.youtube.com/watch?v=ZV5yTm4pT8g (generally good site)</li> <li>https://docs.github.com/en/apps/creating-github-apps/writing-code-for-a-github-app/building-a-login-with-github-button-with-a-github-app</li> <li>https://www.youtube.com/watch?v=CPbvxxslDTU</li> <li>https://www.youtube.com/watch?v=rTzlF-U9Y6Y</li> <li>https://auth0.com/blog/id-token-access-token-what-is-the-difference/</li> </ul>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#alyssas-notes","title":"Alyssa's notes","text":""},{"location":"backend/OAuth%20_%20OIDC%20dump/#more-on-token-exchange","title":"More on token exchange","text":"<ul> <li>The app that receives the initial token (?) has the option to impersonate (keep app identity hidden from downstream app and act as end user) or delegate (app is acting on behalf of the client, which has obtained auth. from end user) identity of user</li> <li> <p>Tokens include an 'audience value' (who is this intended for) and 'scopes' (what things can you see)</p> </li> <li> <p>Generally, when token exchange is involved there is a central authorization server that becomes the single point of trust. This is typically not GH, which primarily acts as an identity provider (encompasses an authentication server) and may not support token exchange natively</p> <ul> <li>an authorization server handles the authorization aspects of token issuance, and can (but does not always) also handle token exchange</li> <li>GH may not act as a full-fledged authorization server in the OAuth 2.0 sense<ul> <li>Supported OAuth grant types in GH are mentioned here: https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps</li> <li>GH doesn't seem to support RFC 8693, which defines the OAuth 2.0 Token Exchange protocol</li> </ul> </li> <li>GH\u2019s access tokens typically grant access to resources within GH itself (e.g., repositories, issues) rather than acting as tokens that authorize access to third-party services or APIs unrelated to GH<ul> <li>GH's access tokens are scoped to its own APIs and are not intended to manage access to arbitrary external resources / APIs</li> </ul> </li> </ul> </li> <li> <p>For token exhange, can use a service like Keycloak or Auth0</p> <ul> <li>will allow us to use GH for initial user authentication and then manage service-specific tokens through a central authorization server</li> </ul> </li> <li> <p>w/o token exchange:</p> <ul> <li>each downstream service must trust token issued by authentication server (GH), and must validate the received token against GH APIs</li> <li>usually means the token's scope needs to be broader</li> </ul> </li> <li>w/ token exchange:<ul> <li>minimizes permissions granted to any one scope (each service requests a new token w/ tailored scopes + permissions)</li> <li>need to trust a central authorization server that supports token exchange, like Keycloak, to handle the token issuance</li> </ul> </li> </ul> <p>Resources: - https://sagarag.medium.com/oauth2-token-exchange-in-practice-5a12a6d2e0d - https://dev.to/fuegoio/demystifying-authentication-with-fastapi-and-a-frontend-26f5 - https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps - https://medium.com/keycloak/github-as-identity-provider-in-keyclaok-dca95a9d80ca - https://yasasramanayaka.medium.com/oauth-2-0-token-exchange-flow-78fadf23e1fc</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#implicit-vs-authorization-code-schemesflows","title":"Implicit vs. authorization code schemes/flows","text":"<ul> <li>implicit scheme: frontend receives access token from IdP and uses it to access OAuth resources, and then gives token to backend API to secure connection b/w frontend &amp; backend</li> <li>authorization code scheme: backend is the one that first receives the access token, &amp; is in charge of accessing resources<ul> <li>more secure (and generally recommended) b/c frontend doesn't have to give token to backend (although in federated authentication this kind of may be needed anyways)</li> </ul> </li> <li>another flow is the password flow, which is the one used in FastAPI tutorials</li> </ul> <p>Resources: - https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps#web-application-flow - https://github.com/tiangolo/fastapi/discussions/9141</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#using-external-oauth-providers","title":"Using external OAuth providers","text":"<ul> <li>GH<ul> <li>not an OIDC provider -&gt; doesn't provide ID token</li> <li>does not support implicit flow: https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps</li> </ul> </li> <li>ORCiD<ul> <li>OIDC provider with nice documentation, but we need to go through an app registration process<ul> <li>for ORCiD members (member API): https://info.orcid.org/documentation/integration-guide/registering-a-member-api-client/<ul> <li>think this is more for use for member organizations (e.g., McGill?)</li> </ul> </li> <li>for non-members (public API) https://info.orcid.org/documentation/integration-guide/registering-a-public-api-client/</li> </ul> </li> <li>both the member API &amp; public API also have a corresponding sandbox API version, for which you can apply for credentials for your application. The only extra step is that this needs to be done through a sandbox ORCiD account, using a mailinator.com email</li> </ul> </li> <li> <p>Google</p> <ul> <li>OIDC provider</li> <li>General info: https://developers.google.com/identity/openid-connect/openid-connect</li> <li>For example implementation using authorization code flow: https://github.com/kolitiri/fastapi-oidc-react</li> <li>https://stackoverflow.com/questions/7130648/get-user-info-via-google-api/67913727#67913727</li> <li>Setting up JS origins / redirect origins for Google API client:<ul> <li>https://developers.google.com/identity/protocols/oauth2/javascript-implicit-flow#origin-validation</li> <li>https://developers.google.com/identity/protocols/oauth2/web-server#uri-validation</li> </ul> </li> </ul> </li> <li> <p><code>client_id</code> and <code>client_secret</code> are important, they are provided by the IdP for the app (frontend?) and can be used to verify a received access token against the IdP (e.g., the access token that the frontend passes to the backend API)</p> </li> </ul> <p>Related FastAPI resources: - https://github.com/tiangolo/fastapi/discussions/9137 - https://github.com/tiangolo/fastapi/blob/master/fastapi/openapi/models.py#L387-L391</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#oauth-vs-oidc-vs-jwt-authentication","title":"OAuth vs. OIDC vs. JWT (authentication)","text":"<ul> <li>JWT is a token format, can be used for authentication (\"JWT authentication\")</li> <li>a way to encode and verify claims for a token</li> <li>not a (OAuth?) protocol / standard, doesn't specify how client obtains the token</li> <li>JWT tokens are signed with a secret key</li> <li>OIDC</li> <li>uses access tokens and ID tokens (ID token is a JWT, access token may (?) be a JWT but doesn't have to be)</li> <li>OAuth</li> <li>typically deals with only access tokens</li> </ul> <p>Resources: - https://stackoverflow.com/questions/39909419/what-are-the-main-differences-between-jwt-and-oauth-authentication</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#more-on-token-types","title":"More on token types","text":"<ul> <li>\"Access tokens, ID tokens, and self-signed JWTs are all bearer tokens\"</li> </ul> <p>Resources: https://cloud.google.com/docs/authentication/token-types</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#resources-for-using-google-as-external-idp","title":"Resources for using Google as external IdP","text":"<ul> <li>https://medium.com/@vivekpemawat/enabling-googleauth-for-fast-api-1c39415075ea</li> <li>https://prokofyev.ch/implementing-google-login-with-javascript-and-fastapi/</li> <li>https://developers.google.com/identity/gsi/web/guides/verify-google-id-token#python</li> </ul> <p>Questions: - What's the relationship of bearer authentication (see also https://stackoverflow.com/a/77426797), implicit OAuth2 flow, and authorization code OAuth2 flow?     - Either flow can use \"bearer\" authentication, I guess?     - w/o token, it's a \"basic\" auth scheme (?)</p>"},{"location":"backend/OAuth%20_%20OIDC%20dump/#questions-re-federated-auth","title":"Questions re: federated auth","text":"<ul> <li>If the n-API and f-API in a local deployment use the same setting for <code>NB_ENABLE_AUTH</code>, what happens when the query gets forwarded to other (e.g., public) nodes that do require authentication?</li> <li>Maybe 'disabling' means making it optional, so that user can still log in to have access to all nodes, if desired?</li> </ul>"},{"location":"data/Limitations%20of%20Neurobagel%20data%20model/","title":"Limitations of Neurobagel data model","text":"<p>During https://github.com/neurobagel/bulk_annotations/issues/10  we discovered a couple of limitations of our data model. The idea of this page is to keep a record of them, so we don't have to discover the same limitation twice. Some limiations are expected and intentional, we don't want to model everything we can because we want a balance of usefulness and complexity.</p>","tags":["Data model"]},{"location":"data/Limitations%20of%20Neurobagel%20data%20model/#lack-of-longitudinal-phenotypic-info","title":"Lack of longitudinal phenotypic info","text":"<p>Phenotypic data is modeled at the subject level,  not at the session level. This is mainly due to BIDS, as longitudinal phenotypic data in BIDS are currently not defined in the spec.</p> <p>Problems this causes</p> <ul> <li>cannot model a change in diagnosis over time.  If a participant has a DX of \"yes autism\" on session 1, but then a DX of \"no autism\" on session 2, we currently have to pick one.  And then the participant will show up with all of their sessions for only that sessions profile.</li> </ul>","tags":["Data model"]},{"location":"data/Limitations%20of%20Neurobagel%20data%20model/#missing-value-forced-to-be-a-catch-all-category","title":"Missing-value forced to be a catch-all category","text":"<p>For example, I have a column about diagnosis.  The correct ontology is \"SNOMED-CT\". My column has four levels:</p> <ul> <li>Schizophrenia</li> <li>Alzheimer's Disease</li> <li>Sibling with Schizophrenia</li> </ul> <p>The last one is not in SNOMED (one could argue that this is more a modeling issue than an ontology issue). But in my data dictionary, I need to map this value to something. The only option I currently have is to declare it as  \"missing value\" - which is probably not a good option.</p> <p>The alternative would be to \"force\" annotators to pick the \"next closest\" term from SNOMED-CT, but this comes with the cost of reducing  annotation accuracy.</p>","tags":["Data model"]},{"location":"data/Limitations%20of%20Neurobagel%20data%20model/#lack-of-model-variables-to-say-things-about","title":"Lack of model variables to say things about:","text":"<ul> <li>relations. For example, I cannot model that my participant has a sibling with a diagnosis of \"Schizophrenia\"</li> <li>medication status. E.g. cannot say: \"my participant received Drug XYZ\"</li> <li>assessments that aren't tied to a specific tool. e.g. \"Body Mass Index\" is not a tool in the same way that \"blood pressure\" is not a tool. But still relevant info</li> <li>\"assessments\" and \"diagnosis\" are probably too narrow.  E.g.: I can't really expect cognitive atlas to have a purely clinical test battery like the MS EDSS scores. Diagnosis is too narrow because we can differentiate \"Diagnosis\" from \"Finding\" or \"Observation\".  An example is \"Smoker\" vs \"Cancer\". The former is an observation, the latter a diagnosis. Importantly: SNOMED has categories for observation and disorders. So we cannot deduce from a term being in the SNOMED namespace that is a diagnosis. (e.g. \"Smoker\" exists in snomed - snomed:77176002)</li> </ul>","tags":["Data model"]},{"location":"data/Troubleshooting%20erroneous%20HC_Diagnosis%20query%20results/","title":"Troubleshooting HC_Diagnosis query results","text":""},{"location":"data/Troubleshooting%20erroneous%20HC_Diagnosis%20query%20results/#qpn","title":"QPN","text":"<p>TSV (April 12, 2024): - num. healthy controls: 67 - num. PD patients: 205 - (rest are PPS, etc.)</p> <p>Query tool / API: - num HC: 294/303 - num PD patients: 276/303</p>"},{"location":"data/Troubleshooting%20erroneous%20HC_Diagnosis%20query%20results/#qs-about-current-query-template","title":"Q's about current query template","text":"<ul> <li>Should having a phenotypic session not be optional?</li> <li>Subject group (HC) is currently modeled at the session level but maybe should be instead a subject-level property, or at least standardized across sessions for a subject<ul> <li>can subject group change across timepoints (?)</li> </ul> </li> </ul>"},{"location":"deploy/Apache%20Jena%20Fuseki%20Deployment/","title":"Apache Jena Fuseki Deployment","text":"<p>draft</p>","tags":["Deployment","Infrastructure","Internal Documentation"]},{"location":"deploy/Apache%20Jena%20Fuseki%20Deployment/#quick-start","title":"Quick start","text":"<p>For a very quick start, you can  1. Pull the image  <pre><code>docker pull stain/jena-fuseki\n</code></pre> 2. Create a <code>shiro.ini</code> file for authentication below is an example file: <pre><code>[users]\nbagel = verysecurepassword, admin\n\n[roles]\nadmin = *\n\n[urls]\n/** = authcBasic, roles[admin]\n</code></pre></p> <ol> <li>Start a container by running the following command to map the port and mount the <code>shiro.ini</code> file <pre><code>docker run -d --name fuseki -p 3030:3030 -v ./shiro.ini:/fuseki/shiro.ini stain/jena-fuseki\n</code></pre></li> </ol>","tags":["Deployment","Infrastructure","Internal Documentation"]},{"location":"deploy/Apache%20Jena%20Fuseki%20Deployment/#connect-with-neurobagel-api","title":"Connect with Neurobagel API","text":"<p>Assuming you've already followed the steps in quick-start and that you're running all this locally on your machine you can go ahead and create a dataset using the configured authentication </p> <ol> <li> <p>Create <code>synthetic</code> dataset <pre><code>curl -X POST -u bagel:verysecurepassword --data \"dbName=synthetic&amp;dbType=tdb\" http://localhost:3030/$/datasets\n</code></pre></p> </li> <li> <p>Upload <code>synthetic_example.jsonld</code> to the <code>synthetic</code> dataset <pre><code>curl -X POST -u bagel:verysecurepasswor --data-binary @{path/to/synthetic_example.jsonld}.jsonld -H \"Content-Type: application/ld+json\" http://localhost:3030/synthetic/data?default\n</code></pre></p> </li> <li> <p>Lastly if you'd like to use the Fuseki server with the Neurobagel API use the <code>.env</code> file below <pre><code>NB_GRAPH_USERNAME=bagel \nNB_GRAPH_PASSWORD=verysecurepassword\nNB_GRAPH_DB=synthetic/query\nNB_RETURN_AGG=true\nNB_API_TAG=latest\nNB_API_ALLOWED_ORIGINS=\"*\"\nNB_GRAPH_PORT=3030\nNB_GRAPH_ADDRESS=127.0.0.1\n</code></pre></p> </li> </ol>","tags":["Deployment","Infrastructure","Internal Documentation"]},{"location":"deploy/Apache%20Jena%20Fuseki%20Deployment/#relevant-questions","title":"Relevant questions:","text":"<ul> <li> <p>Can we run it as a docker image (from default or do you have to make one)? There isn't an official docker image for Fuseki but I found a community-supported image that I used for trying and testing Fuseki. We can use the image available on the docker hub at stain/jena-fuseki or use the DOCKERFILE available on stain's GitHub repo to make our own image.</p> </li> <li> <p>Can we create a new graph/database and push data into it? Yes in Fuseki they refer to them as <code>datasets</code>.</p> </li> </ul> <p>To create a dataset: <pre><code>curl -X POST -u {username}:{passwod} --data \"dbName={datasetname}&amp;dbType=tdb\" {graph_address}:3030/$/datasets\n</code></pre></p> <p>To push data into it e.g., a <code>.jsonld</code> file: <pre><code>curl -X POST -u {username}:{passwod} --data-binary @{path/to/file}.jsonld -H \"Content-Type: application/ld+json\" {graph_address}:3030/{datasetname}/data?default\n</code></pre> - Can you query it with some silly SPARQL query? Yes, we can use the following command: <pre><code>curl -X POST -H \"Content-Type: application/sparql-query\" -H \"Accept: application/sparql-results+json\"  --data 'SELECT * WHERE { ?s ?p ?o } LIMIT 10' -u {username}:{passwod}  {graph_address}:3030/{datasetname}/query\n</code></pre></p> <ul> <li> <p>Is there a web GUI to run queries? maybe an extension / buddy-project? Yes, the aforementioned docker image includes a web UI that allows for running queries on the dataset and offers a few other useful info on datasets but it's rather simple compared to Stardog studio</p> </li> <li> <p>Can we create user credentials/passwords to protect graphs? Yes, but it's a bit different than Stardog and GraphDB. Fuseki requires a <code>shrio.ini</code> file for creating users, setting roles, giving permissions, etc. See shiro docs.</p> </li> </ul>","tags":["Deployment","Infrastructure","Internal Documentation"]},{"location":"deploy/Docker/","title":"Docker","text":"","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#internal-port-vs-host-port","title":"Internal port vs host port","text":"<p>In the context of docker compose and within a docker network services talk to each other on their internal port number, and not the port that is exposed to the host. For example, given a stack with the following config <pre><code>name: api\nservices:\n  api:\n    environment:\n      NB_API_ALLOWED_ORIGINS: '*'\n      NB_API_PORT: \"8000\"\n      NB_GRAPH_ADDRESS: graph\n      NB_GRAPH_DB: test_data/query\n      NB_GRAPH_PASSWORD: admin\n      NB_GRAPH_PORT: \"5820\"\n      NB_GRAPH_USERNAME: admin\n      NB_RETURN_AGG: \"false\"\n    image: neurobagel/api:test\n    networks:\n      default: null\n    ports:\n    - mode: ingress\n      target: 8000\n      published: \"8888\"\n      protocol: tcp\n  graph:\n    image: stardog/stardog:8.2.2-java11-preview\n    networks:\n      default: null\n    ports:\n    - mode: ingress\n      target: 5820\n      published: \"5821\"\n      protocol: tcp\n    volumes:\n    - type: bind\n      source: /home/ubuntu/stardog_root_test\n      target: /var/opt/stardog\n      bind:\n        create_host_path: true\n  query:\n    environment:\n      API_QUERY_URL: http://localhost:8000/\n    image: neurobagel/query_tool:latest\n    networks:\n      default: null\n    ports:\n    - mode: ingress\n      target: 3000\n      published: \"3000\"\n      protocol: tcp\nnetworks:\n  default:\n    name: api_default\n</code></pre> The api will be sending its requests to the port <code>5820</code> and not <code>5821</code>.</p>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#note","title":"Note","text":"<p>This may introduce issues for the API -&gt; graph connection when the running API is not in the same Docker network as the graph, e.g. if you have locally spun up an API using Python but want to communicate with a Dockerized graph endpoint.  In this scenario, you would likely need to manually specify the host port for the graph container in the query URL, rather than using the container port.</p>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#setting-environment-variables","title":"Setting environment variables","text":"","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#docker-compose","title":"docker compose","text":"<ul> <li><code>environment</code> instruction for a specific service (<code>in docker-compose.yml</code>)</li> <li>Defines variables to be set inside the container (compose config file itself cannot see the variables)</li> <li><code>env_file</code> instruction for a specific service (<code>in docker-compose.yml</code>) </li> <li>Only sets variables inside the container (compose config file itself cannot see the variables)</li> <li>Can replace / works without <code>environment</code> instruction to set variables in the container</li> <li>Values inside specified env file can be quoted or unquoted, with same result in <code>docker compose config</code></li> <li><code>--env-file</code> CLI argument (e.g., <code>docker compose --env-file custom.env ...</code>)</li> <li>Only seen by the compose config itself, UNLESS the <code>environment</code> instruction is also used (in which case, variables that are defined under <code>environment</code> which also have a value inside the specified env file are passed to and can be used inside the container)</li> <li>Essentially just for specifying a custom path for the <code>.env</code> file, and works the same as having a file named <code>.env</code> (in which case the <code>--env-file</code> argument is not needed)</li> <li>Does not care about quotes around variable values in the file</li> </ul> <p>Some important references: - https://docs.docker.com/compose/environment-variables/set-environment-variables/ - https://docs.docker.com/compose/compose-file/05-services/ (see sections on <code>env_file</code> and <code>environment</code>) - https://docs.docker.com/compose/environment-variables/env-file/ - https://docs.docker.com/compose/environment-variables/envvars-precedence/</p>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#docker-cli-docker-run","title":"docker CLI (docker run)","text":"<p>All three options below can set variables inside the container.</p> <ul> <li><code>ENV</code> instruction in dockerfile</li> <li>Should work the same as <code>--env</code> / <code>-e</code> command-line argument (e.g., <code>docker run -e MYVAR=MYVALUE</code>)</li> <li>Quotes are needed for variable values with spaces</li> <li>Not required for an environment variable to be available to code in the container, such as if one of the below two options are used</li> <li><code>--env-file</code> CLI argument</li> <li>Interprets value exactly as is inside specified file (including any quotes), does not do any parameter expansion for values inside the file (i.e., for <code>VAR=VALUE</code>, the VALUE is passed in exactly as is, as a literal)<ul> <li>See:</li> <li>https://github.com/docker/for-linux/issues/1208</li> <li>https://github.com/docker/cli/issues/4347#issuecomment-1590210864</li> </ul> </li> <li>IMPORTANT: THIS IS (FOR SOME REASON) NOT THE SAME FUNCTIONALLY AS THE <code>--env-file</code> CLI ARGUMENT FOR DOCKER COMPOSE!<ul> <li>See this commment https://github.com/docker/cli/issues/4347#issuecomment-1590214094 from a Docker maintainer</li> </ul> </li> <li>Unfortunately these caveats are not very well documented \ud83d\ude22</li> <li><code>--env</code>/<code>-e</code> CLI argument</li> <li>Quotes are needed for variable values with spaces, will override the same variable set via <code>ENV</code> instruction in the dockerfile</li> </ul> <p>Some important references: - https://docs.docker.com/engine/reference/commandline/run/#env - https://docs.docker.com/engine/reference/builder/#env - https://stackoverflow.com/a/63640896 (this answer mostly explains <code>ARG</code>/<code>ENV</code> but also covers some info on both <code>docker run</code> and <code>docker compose</code>)   - a summary of https://vsupalov.com/docker-arg-env-variable-guide/</p>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#using-secrets-in-docker-compose","title":"Using <code>secrets</code> in Docker Compose","text":"<p>The key point to note when using secrets is that each secret that a container (i.e., service in the Compose file) is granted access to gets mounted at a special path inside the container: <code>/run/secrets/&lt;secret_name&gt;</code></p> <p>That is, the value of each secret ends up as the contents of a separate file under <code>/run/secrets/</code> inside the container.</p> <p>You can define a secret one of two ways:</p> <ul> <li> <p>By setting it as the value of environment variable that is accessible to the Compose file itself</p> <ul> <li>So, any way that you can provide/expose environment variables to the Compose file, you should be able to include the environment variable for the secret (see Setting environment variables section)</li> <li> <p>including via a <code>.env</code> file</p> <p>Example:</p> <pre><code># .env file\nMY_SECRET=bageley\n...\n</code></pre> <pre><code># docker-compose.yml\n...\nsecrets:\n  my_secret:\n    environment: \"MY_SECRET\"\n</code></pre> <p>Inside a container that has access to <code>my_secret</code>, <code>cat /run/secrets/my_secret</code> will return <code>bageley</code>.</p> <p>If <code>MY_SECRET</code> is not found in the environment (or unset ? - need to check), docker compose will give an error.</p> <p>NOTE: In order to ensure the <code>MY_SECRET</code> value does not end up exposed in e.g., the docker compose config, if a container needs to use other variables defined in the <code>.env</code> file, each needed variable should be explicitly specified under the <code>environment</code> attribute in docker-compose.yml, rather than using the <code>env_file</code> attribute (because it will auto-include all the variables in <code>.env</code> as environment variables, including the secret).</p> </li> </ul> </li> <li> <p>By making the value of the secret the contents of a file, which you then provide to the <code>secrets</code> attribute</p> </li> <li>Example: see https://docs.docker.com/compose/use-secrets/#advanced</li> </ul> <p>Note that for both these methods:</p> <ul> <li>The secret is not automatically set as an environment variable inside the container</li> </ul> <p>References:</p> <ul> <li>https://docs.docker.com/compose/use-secrets/</li> <li>https://docs.docker.com/compose/compose-file/09-secrets/</li> </ul>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#troubleshooting-dockerdocker-compose-recipes","title":"Troubleshooting Docker/Docker Compose recipes","text":"<p>Mostly encountered when trying to deploy our tools on the internal BIC node (where we don't have admin permissions), which involves a network FS from a different machine.</p>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#running-docker-container-as-non-root-user","title":"Running Docker container as non-root user","text":"<p>Sometimes, probably depending on the permissions of a user on the machine they are using to deploy Neurobagel, Docker can be run as the <code>nobody</code> user (even though inside the container the user is <code>root</code>, by default). This means when the container tries to write to a mounted directory on the host, it might not have permissions to do so (unless the directory has <code>rwx</code> permissions for ALL users, which usually isn't the desired setup).</p> <p>You can verify what user is being used to write to the host FS by running an interactive bash shell inside the container that uses the volume mount, and trying to write to a mounted test directory with fully open access permissions, e.g.:</p> <pre><code>docker run -it -v /data/origami/mount_test:/opt/graphdb/home --entrypoint /bin/bash ontotext/graphdb:10.3.1 -c \"touch /opt/graphdb/home/hellofromcontainer.txt\"\n</code></pre> <p>Then, you can <code>cd</code> into the mounted directory on the host and view the file owner/group.</p> <p>One workaround is to explicitly run the container as a non-root user, using the <code>--user</code> flag in <code>docker run</code>, or the <code>user</code> instruction in docker-compose.yml:</p> <p>e.g.,</p> <ol> <li> <p>Add following to the relevant service in <code>docker-compose.yml</code>:</p> <pre><code>user: ${CURRENT_UID}\n</code></pre> </li> <li> <p>Start the Compose stack with</p> <pre><code>CURRENT_UID=$(id -u):$(id -g) docker compose up -d\n</code></pre> </li> </ol> <p>Useful commands for troubleshooting:</p> <pre><code>id $USER  # shows uid and all gid and names for current user\nid -gn  # gets name of primary group\n\n# get id of user and primary group\nid -g  # not all shells set $GID\nid -u  # same as $UID\n</code></pre> <p>References:</p> <ul> <li>https://medium.com/redbubble/running-a-docker-container-as-a-non-root-user-7d2e00f8ee15</li> <li>https://docs.docker.com/compose/compose-file/05-services/#user</li> <li>https://docs.docker.com/engine/reference/run/#user</li> <li>https://dev.to/izackv/running-a-docker-container-with-a-custom-non-root-user-syncing-host-and-container-permissions-26mb</li> <li>https://askubuntu.com/questions/1201352/what-environment-variable-will-report-the-users-primary-group</li> </ul>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Docker/#specifying-specific-subnet-for-docker-networks","title":"Specifying specific subnet for Docker networks","text":"<p>Unless configured to do otherwise, the Docker engine by default will choose a subnet for each Compose network at creation time - this is problematic when an existing subnet needs to be reserved for use on a machine, e.g. for a specific network FS. When this is the case, the network FS becomes unreachable if a conflicting subnet is used by a newly launched Docker network. (Note: By default, each Docker Compose network gets assigned its own subnet.)</p> <p>There are a few ways to change which subnet is used by a Docker network or Docker container:</p> <ul> <li>edit <code>/etc/docker/daemon.json</code> (see https://github.com/docker/compose/issues/4336#issuecomment-457326123)</li> <li>you can set <code>\"default-address-pools\"</code>, which will put containers using both docker and docker compose into your desired subnet</li> <li>setting <code>\"bip\"</code> and <code>\"fixed-cidr\"</code> only seems to affect Docker containers launched not as part of a Compose recipe, which use the default bridge network</li> <li>specify a network subnet in each docker-compose.yml, following https://docs.docker.com/compose/compose-file/06-networks/#ipam</li> <li>option 1: specify to use the same network in each docker-compose.yml - see example here (this is != specifying just the same <code>subnet</code> in each docker-compose.yml, which can cause the following issue)     <pre><code>[+] Running 1/0\n\u2718 Network bic_federation_fednet  Error                                                                                  0.0s\nfailed to create network bic_federation_fednet: Error response from daemon: Pool overlaps with other one on this address space\n</code></pre></li> <li>option 2: use a custom network per docker-compose.yml, but specify non-conflicting <code>subnet</code>s (either /16 or /24)<ul> <li>specifying the same <code>subnet</code>, but non-conflicting <code>ip_range</code> doesn't seem to be sufficient: <pre><code>Error response from daemon: cannot create network c800e759f35a326a36f8beac2aa60fc5032a8cc92ede2210a92ba8f4845e9c5f (br-c800e759f35a): conflicts with network 6873e8489de40af4d4a9f7635145fd3ea9753fb4c03f6eafbc6e5fa8fcdde791 (br-6873e8489de4): networks have overlapping IPv4\n</code></pre></li> <li>specifying just <code>ip_range</code> also seems to not work? <pre><code>failed to create network bic_federation_fednet: Error response from daemon: Invalid subnet  : invalid CIDR address:\n</code></pre></li> </ul> </li> </ul> <p>Resources: - https://docs.docker.com/config/daemon/ipv6/#dynamic-ipv6-subnet-allocation - https://docs.docker.com/compose/compose-file/06-networks/#ipam - https://forums.docker.com/t/docker-default-address-pool-customization-question/112969 - https://docs.docker.com/network/network-tutorial-standalone/#use-user-defined-bridge-networks - https://stackoverflow.com/questions/38088279/communication-between-multiple-docker-compose-projects</p>","tags":["SysAdmin","Deployment"]},{"location":"deploy/Dockerized%20NGINX%20deployment/","title":"Neurobagel deployment","text":"<ul> <li>nginx and config</li> <li>SSL certificates</li> <li>docker compose management</li> <li>differences from the public docker compose recipe</li> <li>plausible</li> </ul> <p>Resources: - https://github.com/nginx-proxy/nginx-proxy/tree/main/docs#path-based-routing</p>"},{"location":"deploy/Dockerized%20NGINX%20deployment/#auto-configured-nginx","title":"Auto-configured NGINX","text":"<ul> <li>https://github.com/nginx-proxy/nginx-proxy<ul> <li>automatically creates new reverse proxy routes for docker containers or docker compose stacks</li> <li>you only need to provide the proxied URL name as a <code>ENV</code> variable</li> <li>e.g. <code>--env VIRTUAL_HOST=foo.bar.com</code> to create a route for <code>foo.bar.com</code></li> <li>see also: detailed docs</li> </ul> </li> <li>https://github.com/nginx-proxy/acme-companion<ul> <li>is a companion project for <code>nginx-proxy</code></li> <li>it automatically requests SSL certificates from letsencrypt for new docker containers or compose stacks</li> <li>you need to only provide another <code>ENV</code> variable</li> <li>e.g. <code>--env \"LETSENCRYPT_HOST=foo.bar.com\"</code> to get an SSL certificate for <code>foo.bar.com</code></li> <li>see also: detailed docs</li> </ul> </li> </ul> <p>Custom configuration of NGINX for each domain can be done following these instructions: - https://github.com/nginx-proxy/nginx-proxy/tree/main/docs#custom-nginx-configuration   - Configuration directories/files should be created locally and then mounted into the NGINX container in the docker-compose.yml   - e.g. To increase timeout, following lines added to a <code>conf.d/my_proxy.conf</code> file:     <pre><code>proxy_read_timeout 900;\nproxy_connect_timeout 900;\nproxy_send_timeout 900;\n</code></pre></p> <p>HOWTO: 1. Create a <code>docker-compose.yml</code> file that contains both <code>nginx-proxy</code> AND <code>acme-companion</code>.      - e.g. here: https://github.com/neurobagel/internal_deployment/blob/1f3bdbf521c0cbeb4590ea9f5d21c3d64020bbad/docker_nginx.yml     - be sure to expose the docker socket as a volume! 2. Launch the nginx+acme docker compose stack. Take note of the network name that gets created 3. Launch your production docker containers/compose stacks and      - add the NGINX+ACME environment variables for the services that need to be publicly reachable:         - <code>VIRTUAL_HOST</code>         - <code>LETSENCRYPT_HOST</code> (should be same as <code>VIRTUAL_HOST</code>)         - <code>VIRTUAL_PORT</code> -&gt; this is the internal port used inside the container, not the one exposed to the host!     - add the publicly reachable services to the NGINX+ACME network. E.g. like so: https://docs.docker.com/compose/networking/#use-a-pre-existing-network         - If using <code>docker run</code>, can specify <code>--net</code> 4. Look at the nginx+acme logs to ensure that the routes and SSL certificates are created correctly 5. Ensure that the subdomain has been correctly configured in Cloudflare</p>"},{"location":"deploy/Fabrique%20%28vGPU%20prep%20and%20other%20issues%29/","title":"Fabrique (vGPU prep and other issues)","text":"<p>1st attempt After setting up the machine and adding collaborators ssh keys, we attempted to prepare the vGPU following the CC instructions here: https://docs.alliancecan.ca/wiki/Using_cloud_vGPUs#Preparation_of_a_VM_running_Ubuntu22</p> <p>The installation of packages failed when running the post-installation script for nvidia-vpgu-kmod package. Running <code>nvidia-smi</code> command outputs: <code>NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.</code> Reached out to support for assistance and they suggested starting from a fresh instance.</p> <p>2nd attempt Shut off the instance, deleted the instance, and started a fresh instance. Once the machine came up, followed the CC instructions to prepare the vGPU. This time installation was successful and <code>nvidia-smi</code> command output was as outlined in the instructions. Set up the machine (docker, ssh keys, etc). Created a snapshot of the machine at this point where <code>nvidia-smi</code> was still working as expected. Then installed Python3-venv, Python3-pip, and NVIDIA container toolkit  which is required to use Ollama containers following the instructions here: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation</p> <p>and realized the <code>nvidia-smi</code> is no longer working. <code>nvidia-smi</code> command output: <code>Failed to initialize NVML: Unknown Error</code> </p> <p>3rd attempt We rebuilt the machine using the snapshot and then installed python3-venv, python3-pip, and NVIDIA container toolkit and <code>nvidia-smi</code> command output was as outlined in the CC instructions and working as expected. However, later that day somehow the <code>nvidia-smi</code> command stopped working as expected giving <code>Failed to initialize NVML: Unknown Error</code> as output</p> <p>4th attempt Rebuilt the machine using the snapshot again and installed NVIDIA container toolkit and <code>nvidia-smi</code> command output was as outlined in the CC instructions and working as expected.</p> <p>sidenode: Support got back to us mentioning there may be an error due to a mismatch between the Nvidia driver and the Nvidia cuda toolkit. They suggested trying version 11 of the toolkit instead. That has been installed as well, waiting to see whether the machine will break or not. It seems the installations were for cuda toolkit version 11.8 but the <code>nvidia-smi</code> command output indicates that the machine seems to be using the old 11.4 as opposed to the newly installed 11.8.</p> <p>1st update on the 4th attempt: A week has passed and the <code>nvidia-smi</code> command output is still as expected. - Raya has tried the machine and hasn't had any issues.  - James mentioned what he was trying on the machine was related to hugging face and not Ollama. *Waiting on Brent to get back to me to see if he had any issues using the machine. Waiting on Barbara and Tvisha to try the machine for more info</p> <p>2nd update on the 4th attempt: It's been a couple of weeks since the last update. The machine seems to be stable. Collaborators have been using it and it hasn't had the previously mentioend issues. The <code>nvidia-smi</code> command runs as expected and the nvidia container toolkit seems to be working fine. The only reported issue from collaborators in the past week (first week of July 2024) seems to be the speed of the machine (to be mentioned to support).</p> <p>July 9th update: We were given notice through email:</p> <p>Hello, the hypervisor your VM is running on, will be upgraded to the latest version of vGPU drivers on: Tuesday, 9th July 2024 VM name: fabrique VM ID: 75b9d54a-6b2d-4477-8f89-d8a453557186 The 470.x driver installed within your VM will stop working and needs to be upgrade to the 550.x version we provide. Instructions on how to install the new driver version can be found here: https://docs.alliancecan.ca/wiki/Using_cloud_vGPUs Please make sure to fully uninstall the 470 version. The following OS versions are EOL and are not supported anymore: CentOS7 Ubuntu18 Debian10 If you need help with the driver installation within the VM, please respond to this ticket. Thank you for your understanding.</p> <p>The <code>nvidia-smi</code> command stopped working as expected and now outputs <code>No devices were found</code>. Drivers were updated following the CC instructions and everything seems to be working as expected. It's worth noting that the <code>nvidia-smi</code> command now outputs the new versions of drivers specifically 550 for nvidia-smi and driver version and 12.4 for CUDA version.</p>","tags":["Infrastructure"]},{"location":"deploy/Legacy%20Stardog%20graph%20backend%20deployment%20instructions/","title":"Legacy Stardog graph backend deployment instructions","text":"<p> The below instructions are the old mkdocs version of the Neurobagel node setup instructions using stardog, which are now deprecated.  </p>"},{"location":"deploy/Legacy%20Stardog%20graph%20backend%20deployment%20instructions/#setup-for-the-first-run","title":"Setup for the first run","text":"<p>To interact with your graph backend, you have two general options:</p> <ol> <li>Send HTTP requests to the HTTP REST endpoints of the Stardog graph backend (e.g. with <code>curl</code>). See https://stardog-union.github.io/http-docs/ for a full reference of Stardog API endpoints</li> <li>Use the free Stardog-Studio web app. See the Stardog documentation for instructions to deploy Stardog-Studio as a Docker container.</li> </ol> <p>Info</p> <p>Stardog-Studio is the most accessible way  of manually interacting with a Stardog instance.  Here we will focus instead on using the HTTP API for configuration, as this allows programmatic access. All of these steps can also be achieved via Stardog-Studio manually. Please refer to the  official docs to learn how.</p>"},{"location":"deploy/Legacy%20Stardog%20graph%20backend%20deployment%20instructions/#set-the-database-admin-password","title":"Set the database admin password","text":"<p>When you first launch the graph server, a default <code>admin</code> user with superuser privilege will automatically be created for you.  This <code>admin</code> user is meant to create other database users and modify their permissions.</p> <p>You should first change the password of the database <code>admin</code>:</p> <pre><code>curl -X PUT -i -u \"admin:admin\" http://localhost:5820/admin/users/admin/pwd \\\n--data '{\"password\": \"NewAdminPassword\"}'\n</code></pre>"},{"location":"deploy/Legacy%20Stardog%20graph%20backend%20deployment%20instructions/#create-a-new-database-user","title":"Create a new database user","text":"<p>We do not recommend using <code>admin</code> for normal read and write operations, instead we can create a regular database user.</p> <p>The <code>.env</code> file created as part of the <code>docker compose</code> setup instructions declares the <code>NB_GRAPH_USERNAME</code> and <code>NB_GRAPH_PASSWORD</code> for the database user. The Neurobagel API will send requests to the graph using these credentials. When you launch the RDF store for the first time,  we have to create a new database user:</p> <pre><code>curl -X POST -i -u \"admin:NewAdminPassword\" http://localhost:5820/admin/users \\\n-H 'Content-Type: application/json' \\\n--data '{\n    \"username\": \"DBUSER\",\n    \"password\": [\n        \"DBPASSWORD\"\n    ]\n}'\n</code></pre> <p>Confirm that the new user exists:</p> <pre><code>curl -u \"admin:NewAdminPassword\" http://localhost:5820/admin/users\n</code></pre> <p>Note</p> <p>Make sure to use the exact <code>NB_GRAPH_USERNAME</code> and <code>NB_GRAPH_PASSWORD</code> you defined in the <code>.env</code> file when creating the new database user. Otherwise the Neurobagel API will not have the correct permission to query the graph.</p>"},{"location":"deploy/Legacy%20Stardog%20graph%20backend%20deployment%20instructions/#create-new-database","title":"Create new database","text":"<p>When you first launch the graph store, there are no graph databases. You have to create a new one to store your metadata.</p> <p>If you have defined a custom <code>NB_GRAPH_DB</code> name in the <code>.env</code> file, make sure to create a database with a matching name. By default the Neurobagel API will query a graph database named <code>test_data</code>.</p> <pre><code>curl -X POST -i -u \"admin:NewAdminPassword\" http://localhost:5820/admin/databases \\\n--form 'root=\"{\\\"dbname\\\":\\\"test_data\\\"}\"'\n</code></pre>"},{"location":"deploy/Legacy%20Stardog%20graph%20backend%20deployment%20instructions/#grant-database-permissions-to-user","title":"Grant database permissions to user","text":"<p>Now we need to give our new database user read and write permission for  this database:</p> <pre><code>curl -X PUT -i -u \"admin:NewAdminPassword\" http://localhost:5820/admin/permissions/user/DBUSER \\\n-H 'Content-Type: application/json' \\\n--data '{\n    \"action\": \"ALL\",\n    \"resource_type\": \"DB\",\n    \"resource\": [\n        \"test_data\"\n    ]\n}'\n</code></pre> <p>??? note \"Finer permission control is also possible\"</p> <pre><code>For simplicity's sake, here we give `\"ALL\"` permission to the new database user.\nThe Stardog API provide more fine grained permission control.\nSee [the official Stardog API documentation](https://stardog-union.github.io/http-docs/#tag/Permissions/operation/addUserPermission).\n</code></pre>"},{"location":"deploy/Node-upgrade-after-release/","title":"Nodes to upgrade after releases","text":"<p>Here are the nodes we need to upgrade after a new release:</p> <ul> <li>[ ] INDI</li> <li>[ ] OpenNeuro</li> <li>[ ] QPN</li> <li>[ ] QPN (ENIGMA)</li> <li>[ ] EBRAINS</li> <li>[ ] BIC internal (full stack)</li> <li>[ ] Testing node</li> <li>[ ] Neurobagel federation</li> </ul>"},{"location":"deploy/Setting%20up%20SSH%20keys/","title":"Setting up SSH keys","text":"<p>To add public keys for the existing users</p> <ul> <li> <p>switch to substitute user</p> <ul> <li><code>sudo su -</code></li> </ul> </li> <li> <p>Navigate to home directory</p> <ul> <li><code>cd /home</code> Should be able to see a home directory for each user there</li> </ul> </li> <li> <p>Navigate to the home directory of the user</p> <ul> <li><code>cd arman</code></li> </ul> </li> <li> <p>Navigate to the .ssh folder of the user</p> <ul> <li><code>cd .ssh</code></li> </ul> </li> <li> <p>Add the ssh key to the authorized key file </p> <ul> <li><code>nano authorized_keys</code></li> </ul> </li> </ul>"},{"location":"dev/Git%20Tricks/","title":"Things we've learned","text":"<p>This is a place to keep solutions we find / learned when dealing with git problems (or the references that have the answers).</p>"},{"location":"dev/Git%20Tricks/#github-specific","title":"Github specific","text":""},{"location":"dev/Git%20Tricks/#my-pr-has-too-many-changes-merging-into-the-wrong-branch","title":"My PR has too many changes / merging into the wrong branch","text":"<p>PRs by default are made against the default branch (<code>main</code> / <code>master</code>). You can select a different one when you create the PR, or change it later. See here: https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/changing-the-base-branch-of-a-pull-request</p>"},{"location":"dev/Git%20Tricks/#i-want-to-partially-revert-a-commit","title":"I want to partially revert a commit","text":"<p>You made some changes, but got too excited and lumped together a bunch of things in one commit that aren't really linked. Classic case: reformatted the file and added some functional changes. Your observant reviewer says to please revert the formatting (but keep functional changes). Now what?</p> <p>Step 1: <code>git revert &lt;offending commit hash&gt;</code>. See here https://www.atlassian.com/git/tutorials/undoing-changes/git-revert. Now you have created a new (revert) commit that undoes all what the offending commit has introduced. That's good, but now the part of the commit we liked is also undone. (note: do not use rebase here, we don't want to rewrite history)</p> <p>Step 2: <code>git checkout -p &lt;offending commit hash&gt;</code>. See here https://git-scm.com/docs/git-checkout#Documentation/git-checkout.txt---patch This checks out the offending commit (from further down in the git log). The <code>-p</code> flag makes this an interactive process: your default text editor will show you the changes in the offending commit, one (c)hunk at a time and you can then decide whether you'd like to apply that change (again) or not. The way you use this in our example is to say yes to the functional changes, and no to the formatting changes.</p> <p>At the end of this process, you have new staged changes (the ones you said yes to during the patch checkout) and you can now either --amend your revert commit (to make it only a partial revert) or make a new commit for these specific changes.</p>"},{"location":"dev/Git%20Tricks/#cloning-a-private-repo-without-ssh-key","title":"Cloning a private repo without ssh key","text":"<p>You may need to do this in order to clone a private data repo to one of our shared remote cloud servers, since any ssh key files copied to these servers could be visible to team members using the same account.</p> <p>First, on the remote server where you need to clone the repo, login to GitHub using the gh CLI: <code>gh auth login</code></p> <p>Choose HTTPS as the preferred protocol for Git operations, and then select <code>Login with a web browser</code> when prompted to authenticate GitHub CLI.</p> <p>Copy the one-time code provided, and press Enter. Then, in a browser on your local machine, copy the URL provided (https://github.com/login/device) and enter the one-time code.</p>"},{"location":"dev/Git%20Tricks/#good-resources","title":"Good resources","text":"<ul> <li>https://dangitgit.com/ (list with solutions to common problems)</li> <li>Atlassian Git Tutorials (very well made tutorials, from beginner to advanced)</li> <li>Offical git docs (bit technical)</li> </ul>"},{"location":"dev/Tools/","title":"Tools","text":"<p>Smart things we know about tools</p>"},{"location":"dev/Tools/#vuejs-devtools","title":"Vue.js devtools","text":"<p>A niche browser extension for Vue development. It offers access to Vue components, timelines, routes, and Vuex.</p>"},{"location":"dev/Tools/#json","title":"JSON","text":"<p>Web based json-schema validator that can create custom URLs to point to specific examples. Great for issues: https://www.jsonschemavalidator.net/</p>"},{"location":"dev/Tools/#dependabot","title":"Dependabot","text":"<p>The dependabot config file is stored in the <code>.github</code> directory e.g., query tool's dependabot.yml.</p>"},{"location":"dev/Tools/#ignore","title":"Ignore","text":"<p>To prevent a specific version bump, add the <code>ignore</code> directive to the dependabot.yml file.  This snippet from query tool's dependabot config file instructs dependabot to ignore <code>nuxt</code> and <code>vue</code> major version updates.</p> <pre><code>version: 2\nupdates:\n  - package-ecosystem: 'npm'\n    directory: '/'\n    schedule:\n      interval: 'weekly'\n    ignore:\n      - dependency-name: 'nuxt'\n        update-types: [\"version-update:semver-major\"]\n      - dependency-name: 'vue'\n        update-types: [\"version-update:semver-major\"]\n</code></pre> <p>In case of a version update that causes major issues in the project i.e., breaks things, reset the version and add the dependency to be ignored. See this PR of the query tool for a demonstration.</p> <p>See GitHub documentation for more information.</p>"},{"location":"dev/Tools/#netlify","title":"Netlify","text":"<p>We use netlify to do deployment previews  during Pull Requests.  That means that when a PR is opened,  Netlify deploys the suggested changes to a temporary URL  and pastes a link into the PR, so that we can look at the changes as they would look in production.</p> <p>To enable netlify for a new Repo,  just connect a Netlify account to Github and have it watch the repo. For the js tools, you have to provide the build argument <code>npm run generate</code>. See here for documentation</p> <p>Note that the current deployments are configured under @surchs' netlify account.</p>"},{"location":"dev/Tools/#markdown","title":"Markdown","text":"<p>Pandas can export a dataframe as a markdown table.  This can be useful to generate markdown table examples on GH from actual files. See: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_markdown.html</p>"},{"location":"dev/Tools/#npm","title":"NPM","text":"<p><code>npm install</code> doesn't update the <code>node_modules</code> directory by default. It installs the dependencies listed in the <code>package.json</code> file into the <code>node_modules</code> directory. If the dependencies are already installed, <code>npm install</code> will not update them unless you specify the --force flag.</p>"},{"location":"dev/Tools/#github-actions","title":"GitHub Actions","text":""},{"location":"dev/Tools/#workflow-file-syntax","title":"Workflow file syntax","text":"<p>Job names otherwise referred to as job identifier by GitHub may only contain alphanumeric characters, '', and '-'. IDs must start with a letter or '' and and must be less than 100 characters.</p>"},{"location":"dev/Version%20compatibility/","title":"Version compatibility","text":"<p>n-API: - v0.3.0</p> <p>f-API: - v0.3.0</p> <p>CLI: - v0.2.2</p> <p>Query tool: - v0.3.0</p> <p>n-API: - v0.2.1</p> <p>f-API: - v0.1.0</p> <p>CLI: - v0.2.1</p> <p>Query tool: - v0.2.2</p>"},{"location":"frontend/CSS/","title":"CSS","text":"<p>Given the visual nature of CSS and styling related tricks and strategies, we've decided to include resources as opposed to notes for this section so the following are the resources that proved helpful in making the query tool UI responsive</p> <ul> <li>Learn CSS Grid - A 13 minute Deep Dive (YT video)</li> <li>Learn Flexbox CSS in 8 minutes (YT video)</li> <li> A practical guide to responsive web design (YT video)</li> </ul>","tags":["Front-end","Layout"]},{"location":"frontend/CSS/#user-agent-stylesheets","title":"User-Agent Stylesheets","text":"<p>User-Agent stylesheet refers to the default CSS file that every browser is shipped with. It contains the base rules that give HTML elements their initial appearance (margins, font sizes, colors, form-control styling, etc.). Since each browser (and even each version) can define these defaults differently, the same HTML may look slightly inconsistent across environments. Developers and libraries override User-Agent stylesheets for corss-browser consistency.</p>","tags":["Front-end","Layout"]},{"location":"frontend/CSS/#tailwind-approach-for-addressing-user-agent-stylesheets","title":"Tailwind approach for addressing User-Agent stylesheets","text":"<p>Tailwind uses preflight which uses modern-normalize as a base, then applies it's own opinionated reset.</p>","tags":["Front-end","Layout"]},{"location":"frontend/CSS/#mui-approach-for-addressing-user-agent-stylesheets","title":"MUI approach for addressing User-Agent stylesheets","text":"<p>Built on nomralize.css plus MUI specific-globals which is applied using their <code>CssBaseline</code> component.</p>","tags":["Front-end","Layout"]},{"location":"frontend/CSS/#tailwind-and-mui-interoperability","title":"Tailwind and MUI interoperability","text":"<p>When using Tailwind with MUI the MUI v6 docs instruct users to turn off the Tailwind reset i.e., set <code>preflight</code> to <code>false</code> and instead use their <code>CssBaseline</code> to reset the User-Agent stylesheets.</p> <p>Sources: MDN docs on CSS and user-agent stylesheets Tailwind preflight MUI CssBaseline</p>","tags":["Front-end","Layout"]},{"location":"frontend/Nuxt%20Tricks/","title":"Nuxt Tricks","text":"","tags":["Frontend"]},{"location":"frontend/Nuxt%20Tricks/#injecting-html-head-attributes","title":"Injecting HTML head attributes","text":"<p><code>&lt;head&gt;</code> is the default place for some things like meta tags,  but also for linking external js scripts, for example from  a CDN. In Nuxt, we can inject e.g. a JS script from a CND into the <code>&lt;head&gt;</code> tag of all attributes using the <code>nuxt.config.js</code> file:</p> <pre><code>head: {\n    title: 'My Tool name',\n    script: [\n      {\n        src: 'https://my.cdn.com/happyscript',\n      },\n    ],\n</code></pre> <p>See the official docs here</p>","tags":["Frontend"]},{"location":"frontend/Nuxt%20Tricks/#using-environment-variables-on-the-client-side","title":"Using environment variables on the client side","text":"<p>By default, reading from a <code>.env</code> file (with <code>in nuxt means that the variables declared in the</code>.env` file get exposed to the server AND the client. This isn't a good thing, because you might have some secrets in there that you don't want to share with the client.</p> <p>What's worse: when you provide an environment variable by declaring it in the environment when you call <code>nuxt</code>, it does not get exposed to the client! In other words, <code>.env</code> and <code>export MYVAR=hello</code> behave differently.</p> <p>For this reason, Nuxt has deprecated reading environment variables using the dotenv module: https://v2.nuxt.com/docs/configuration-glossary/configuration-env/. Instead we now explicitly set which variables (whether from .env or shell variable) should be only visible to the server, and which should visibile to the server and the client (see here and here).</p> <pre><code>export default {\n  publicRuntimeConfig: {\n    myPublicVariable: process.env.PUBLIC_VARIABLE, // will be visible on the server AND the client\n  },\n  privateRuntimeConfig: {\n    myPrivateToken: process.env.PRIVATE_TOKEN // will be visiblye ONLY on the server\n  }\n}\n</code></pre>","tags":["Frontend"]},{"location":"frontend/Nuxt%20Tricks/#routing","title":"Routing","text":"<p>Routing in Nuxt is done by wrapping <code>vue-router</code> (see docs). In Annotation tool in particular routing is done using the <code>to</code> prop of <code>b-nav-item</code> in <code>tool-navbar</code> component and <code>b-button</code> in <code>next-page</code> component.</p>","tags":["Frontend"]},{"location":"frontend/Query%20Tool%20Result%20File%20Generation/","title":"Query Tool Result File Generation","text":""},{"location":"frontend/Query%20Tool%20Result%20File%20Generation/#how-to-generate-query-tool-result-files","title":"How to generate query tool result files","text":"<p>Follow the steps below:</p> <ul> <li>Bring up the stack using <code>Docker compose pull &amp;&amp; docker compose up -d</code><ul> <li>Make sure to bring the stack up in non-aggregate mode with authentication disabled</li> </ul> </li> <li>Send an empty query to <code>Local graph node 1</code> node</li> <li>Select the BIDs Synthetic dataset</li> <li>Download both human-readable labels and URIs files</li> <li>Make sure to manually add aggregate rows to both files</li> </ul>"},{"location":"frontend/Query%20Tool/","title":"Query Tool","text":"<p>Code: https://github.com/neurobagel/query-tool</p> <p>Running version: https://query.neurobagel.org/</p>","tags":["Frontend"]},{"location":"frontend/Query%20Tool/#example-data","title":"Example data","text":"<p>The query tool has two files that a user can download:</p> <ol> <li>A .tsv with the datasets the user has found in their query and selected</li> <li>A .tsv with all of the subjects in the selected datasets that also match the query</li> </ol> <p>Example of the dataset.tsv:</p> DatasetID DatasetName PortalURI NumMatchingSubjects AvailableImageModalities http://neurobagel.org/vocab/001 First Dataset https://openneuro.org/datasets/ds0001 142 [T1, T2, DWI] http://neurobagel.org/vocab/002 Great Dataset https://openneuro.org/datasets/ds0002 2 [T1, Flow] <ul> <li><code>DatasetID</code>: required - dataset uuid</li> <li><code>DatasetName</code>: required - human readable name of the dataset</li> <li><code>PortalURI</code>: optional - link to website about dataset</li> <li><code>NumMatchingSubjects</code>: required - number of subjects matching query inside this dataset</li> <li><code>AvailableImageModalites</code>: aggregate variable - list of unique available imaging modalities for the dataset</li> </ul> <p>Example of a subject .tsv:</p> DatasetID SubjectID Age Sex Diagnosis Assessment SessionID SessionPath NumSessions Modality http://neurobagel.org/vocab/001 sub-01 60 Male PD MMSE ses-01 /data/BIDS/ds0001/sub-01/ses-01/ 2 [T1, T2, DWI] http://neurobagel.org/vocab/001 sub-01 60 Male PD MMSE ses-02 /data/BIDS/ds0001/sub-01/ses-02/ 2 [T1, EEG] http://neurobagel.org/vocab/001 sub-02 40 Female CTL MMSE ses-01 /data/BIDS/ds0001/sub-02/ses-01/ 2 [T1] http://neurobagel.org/vocab/002 sub-02 40 Female CTL UPRSIII ses-02 /data/BIDS/ds0002/sub-02/ses-02/ 2 [EEG, T2] http://neurobagel.org/vocab/002 sub-01 20 Male CTL UPRSIII ses-01 /data/BIDS/ds0002/sub-01/ses-01/ 2 [T1] <ul> <li><code>DatasetID</code>: required - dataset uuid, not persistent across different graphs. It is identical across output files and can be used as the key to join the two output files.</li> <li><code>SubjectID</code>: required - human readable name / label for the subject</li> <li><code>Age</code>: optional - if available: the age as float (according to Neurobagel). Otherwise <code>\"\"</code> empty string</li> <li><code>Sex</code>: optional - if available: the sex as string (according to Neurobagel). Otherwise <code>\"\"</code> empty string</li> <li><code>Diagnosis</code>: optional  - if available: array of string values that represent diagnoses for a session (according to Neurobagel).</li> <li><code>Assessment</code> : optional - if available: array of string values that represent assessments for a session.</li> <li><code>SessionID</code>: required (?) - the human readable name of the session</li> <li><code>SessionPath</code>: required - the file system path or datalad id of the session directory and the files in it</li> <li><code>NumSessions</code>: aggregate variable - int number of total available sessions for a subject</li> <li><code>Modality</code>: required (? unclear, what if no imaging?) - array of string values that represent imaging modalities available in this session</li> </ul>","tags":["Frontend"]},{"location":"frontend/Query%20Tool/#troubleshooting-the-query-tool","title":"Troubleshooting the query tool","text":"<p>When the query tool internally encounters a problem, it will display a generic error of \"Oops, something went wrong\" in the UI. To try to pinpoint the problem from the browser side, open the Developer tools in your browser and check for errors in the JavaScript Console tab as well as in the Network tab.  Since the Network panel only logs network activity while it is open, in the query tool page next to the panel, resubmit the query that previously resulted in the error. Then, click on the request that appears in the Network log to inspect the headers.</p>","tags":["Frontend"]},{"location":"frontend/Query%20Tool/#a-note-on-cors-errors","title":"A note on CORS errors","text":"<p>When there is a problem with how the API/graph or query tool was deployed, you may encounter errors when using the query tool that commonly take the form of a CORS error.  In the Console, this might look like error messages that contain <code>...blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.</code></p> <p>This can, but does not necessarily mean that the issue is with the allowed origins on the API side. CORS errors may appear more generically when there is a problem on the client side (or server side) that results in a failure in attempting a cross-origin request to the API. Similarly, these errors can arise when the response from the server simply does not having the expected header due to some reason (not limited to the actual origin being disallowed).</p>","tags":["Frontend"]},{"location":"frontend/React/","title":"React","text":""},{"location":"frontend/React/#what-triggers-re-renders-in-react","title":"What triggers re-renders in React","text":"<p>A re-render happens when a component runs again after its initial render to update its output.</p> <p>Below are the main scenarios that cause a component to re-render:</p> <ol> <li> <p>State updates: changes to component state (created using useState, useReducer, or any other state hook)</p> </li> <li> <p>Parent re-rendering: when a parent component re-renders, it triggers a re-render in its child components by default</p> </li> <li> <p>Context updates: changes in a context provider\u2019s value cause all components that consume that context to re-render</p> </li> <li> <p>Hook updates: updates from custom hooks or built-in hooks (like useReducer or useSyncExternalStore) cause the component using them to re-render</p> </li> </ol>"},{"location":"frontend/React/#error-boundary","title":"Error boundary","text":"<p>Used to catch rendering errors and display a fallback UI. See relevant React documentation page here for more information.</p> <p>According to this stack overflow post, there are no native functional implementation for the error boundary component in react. See also the following pages of the legacy react docs: - Do hooks cover all cases for classes? - Introducing Error Boundaries</p>"},{"location":"frontend/React/#one-file-per-custom-hook","title":"One file per custom hook","text":"<p>For now, we will have each hook in a separate file, with a test of the same name next to it.</p> <pre><code>useMyHook.ts\nUseMyHook.test.ts\n</code></pre> <p>Reason:</p> <ul> <li>easier to import</li> <li>clearer to manage / write tests for</li> </ul>"},{"location":"frontend/Vite%20tricks/","title":"Vite tricks for runtime ENV vars (from chatGPT)","text":"<p>You are correct that once a React app is statically built, the environment variables are baked into the build and cannot be changed without rebuilding the app. This is because during the build process, environment variables are inlined into the JavaScript bundle.</p> <p>However, for Docker-based deployments, you can use a workaround to inject environment variables at runtime. Here's a general approach:</p> <ol> <li>Instead of baking the environment variables into the build, modify your application to read the environment variables from the runtime environment (e.g., window.env in the browser).</li> <li>In your Docker setup, use a small server-side script that runs when the container starts, which generates a JavaScript file containing the environment variables based on the current environment variables of the container.</li> <li>Serve this generated JavaScript file before your application loads. Here's an example of how you might implement this:</li> </ol> <p>First, create a placeholder for the environment variables in your public folder, e.g., public/env-config.js:</p> <p>```js= window.env = {   REACT_APP_API_URL: '',   // ... other variables }; <pre><code>In your React application, access the environment variables using window.env.REACT_APP_API_URL instead of process.env.REACT_APP_API_URL.\n\nThen, in your Dockerfile, add a step that will replace the env-config.js with actual values when the container starts:\n\n```dockerfile!\n# Build stage\nFROM node:alpine as build-stage\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\n# Production stage\nFROM nginx:alpine as production-stage\nCOPY --from=build-stage /app/dist /usr/share/nginx/html\nCOPY env.sh /\nCOPY .env /\nRUN chmod +x /env.sh\n\n# When the container starts, env.sh will run and inject environment variables\nCMD [\"/bin/sh\", \"-c\", \"/env.sh &amp;&amp; nginx -g 'daemon off;'\"]\n</code></pre></p> <p>Create an env.sh script that will generate the env-config.js file with the actual environment variable values when the container starts:</p> <pre><code>#!/bin/sh\n# Generate env-config.js with current environment variables\necho \"window.env = {\" &gt; /usr/share/nginx/html/env-config.js\nprintenv | grep -v \"no_proxy\" | while read -r line; do\n  echo \"  ${line},\" &gt;&gt; /usr/share/nginx/html/env-config.js\ndone\necho \"};\" &gt;&gt; /usr/share/nginx/html/env-config.js\n</code></pre> <p>Make sure you chmod +x env.sh to make it executable.</p> <p>Now, when you run your Docker container, you can pass environment variables like this:</p> <pre><code>docker run -e REACT_APP_API_URL=https://api.example.com -p 8080:80 your-image-name\n</code></pre> <p>The env.sh script runs when the container starts, reading the current environment variables, and generates the env-config.js that the React app can use. The application will then read the runtime configuration from window.env.</p>","tags":["Frontend"]},{"location":"frontend/Zustand/","title":"Zustand","text":"","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#zustand-design-principles","title":"Zustand design principles","text":"<p>Some basic principles we use to organize our stores. With sources where possible.</p>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#normalize-store-as-much-as-possible-but-no-more","title":"Normalize store as much as possible, but no more","text":"<p>Store objects should have a single theme or purpose. Or: all information one \"thing\" should be located in one place and not duplicated. When designing or expanding a store, we're following loosely the rules for relational database modeling, with some practical exceptions:</p> <ul> <li>if information about two \"entities\" is always handled and changed together (e.g. a standardized variable and its URI) then they can be modeled in the same object</li> <li>we don't normalize many-to-many relations with associative tables/objects. In such a case, we just represent the relation with an array of foreign keys</li> </ul> <p>Reason:</p> <ul> <li>looking up and changing data is more straightforward</li> <li>store objects are less deeply nested, making mutations simpler</li> <li>the store is (hopefully) easier to read (more in the source)</li> </ul> <p>Source:</p> <ul> <li>https://redux.js.org/usage/structuring-reducers/normalizing-state-shape</li> </ul>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#actions-have-semantic-names","title":"Actions have semantic names","text":"<p>Store actions should reflect a real action that a user takes (e.g. <code>userSelectedConfig</code>) or an event that has happened (e.g. <code>describedColumn</code>). The action should not just be a wrapper for <code>set()</code> of a specific variable (i.e. not <code>\"setDataTable\"</code>). That also means that a single store variable may be \"written to\" by more than one action.</p> <p>Example:</p> <pre><code>tbd\n</code></pre> <p>Sources:</p> <ul> <li>https://redux.js.org/style-guide/#model-actions-as-events-not-setters</li> <li>https://tkdodo.eu/blog/working-with-zustand#model-actions-as-events-not-setters</li> </ul>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#somewhat-complex-getters-are-custom-hooks","title":"(somewhat) complex getters are custom hooks","text":"<p>If my component needs access to a computed value that is derived from other values in the store, then we put the logic to generate the computed value inside of a custom hook, not inside the store.</p> <p>Store actions can't use hooks, if you want to then that's a signal to factor out</p> <p>Hooks (custom and otherwise) are only usable inside a React function component. When you find that you want to use a custom hook in an action, that is a signal to consider  factoring (some of) the logic in the hook out into a regular JS utility function.  Then you can use the utility function inside the hook and also inside the action.</p> <p>Reason:</p> <ul> <li>This keeps the store simple and focused on state variables and actions</li> <li>Keeps businesslogic separate and easily testable</li> </ul> <p>Example:</p> <pre><code>todo\n</code></pre>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#actions-can-be-async-eg-as-fetch","title":"Actions can be async (e.g. as fetch)","text":"<p>Actions are usually there to handle some app event and respond to it by setting state. You can also make the action responsible for fetching external data, processing it, and then setting the app state. This is useful e.g. for fetching data from an API and then putting it in the state.</p> <p>Sources:</p> <ul> <li>https://github.com/pmndrs/zustand?tab=readme-ov-file#async-actions</li> </ul>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#expose-store-variables-with-hooks-only","title":"Expose store variables with hooks only","text":"<p>We're following a suggestion by tktodo to expose atomic selectors with custom hooks instead of exposing the entire store.</p> <p>Reason</p> <ul> <li>You are less likely to accidentally subscribe the entire store when you don't need to, avoiding rerenders</li> <li>the custom hooks are more clearly named than destructing the store hook in the component</li> </ul> <p>Example:</p> <pre><code>// Export the selector, not the entire store\nexport const useBears = () =&gt; useBearStore((state) =&gt; state.bears)\n</code></pre> <p>Sources:</p> <ul> <li>https://tkdodo.eu/blog/working-with-zustand#only-export-custom-hooks</li> </ul>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#controlled-components-do-not-access-store-directly-their-parents-do","title":"Controlled components do not access store directly, their parents do","text":"<p>This is a \"house rule\" for us that we may revisit. If a component has state managed by a parent componet (i.e. is primarily a presentational component that gets props), then this component will not directly access the store. Instead this responsibility falls to the parent who will prop-forward both the store variables as well as store actions (in the form of handlers) to the child.</p> <p>This pattern will likely have limits. E.g. we don't want to do very long prop-drilling chains. But it will help keep responsibility clear and allow us to make more reusable components without the close coupling that direct store access would entail.</p> <p>Reasons</p> <ul> <li>Easier to write reusable components, because they are not coupled to store access</li> <li>Separation of concerns. As a non-page component, I only need to worry about my props</li> </ul>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#actions-should-not-call-other-actions","title":"Actions should not call other actions","text":"<p>Actions represent events, and are not just variable setters. That also means that actions should not directly call other actions to simply avoid duplicating code. Instead, the component should dispatch the appropriate actions, and each action is then only concerned with processing its own event.</p> <p>There may be scenarios when one action will always lead to another action being triggered. For now we would expect this situation to be handled in the component and not in the actions.</p>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#lifting-state-up","title":"Lifting state up","text":"<p>To collect data from multiple children, or to have two or more child components communicate with each other, declare the shared state in their parent component instead. The parent component can pass that state back down to the children via props. This keeps the child components in sync with each other and with their parent.</p>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#updating-state","title":"Updating state","text":"<p>For flat updates we can simply use the <code>set</code> function provided with the new state and it will be shallowly merged with the existing state i.e., merging the new state object with the existing one at the top level only.</p> <p>For deeply nested updates we have couple options: - Normal approach: copy all ancestors until you get to the nested state and update it then</p> <pre><code>type State = {\n  deep: {\n    nested: {\n      obj: { count: number }\n    }\n  }\n}\n\n  normalInc: () =&gt;\n    set((state) =&gt; ({\n      deep: {\n        ...state.deep,\n        nested: {\n          ...state.deep.nested,\n          obj: {\n            ...state.deep.nested.obj,\n            count: state.deep.nested.obj.count + 1\n          }\n        }\n      }\n    })),\n</code></pre> <ul> <li>Use Immer</li> <li>Use Optics-ts</li> <li>Use Ramda</li> </ul> <p>Both Optics and Ramda work with types</p>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#you-can-auto-generate-selectors","title":"You can auto generate selectors","text":"","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#difference-between-create-and-createstore","title":"Difference between <code>create</code> and <code>createStore</code>","text":"","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#create","title":"<code>create</code>","text":"<ul> <li> <p>Purpose: The <code>create</code> function is the primary and most commonly used way to create a Zustand store</p> </li> <li> <p>Usage: It is a higher-level API that simplifies the process of creating a store</p> </li> <li> <p>Return Value: It returns a hook that you can use in your React components to access the store</p> </li> <li>Example: <pre><code>import create from 'zustand';\n\nconst useStore = create((set) =&gt; ({\n  count: 0,\n  increment: () =&gt; set((state) =&gt; ({ count: state.count + 1 })),\n}));\n\n// Usage in a component\nfunction Counter() {\n  const { count, increment } = useStore();\n  return (\n    &lt;div&gt;\n      &lt;p&gt;{count}&lt;/p&gt;\n      &lt;button onClick={increment}&gt;Increment&lt;/button&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre></li> </ul>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#createstore","title":"<code>createStore</code>","text":"<ul> <li> <p>Purpose: The <code>createStore</code> function is a lower-level API that directly creates a store without automatically generating a React hook</p> </li> <li> <p>Usage: It is useful when you need more control over the store or when you want to use the store outside of React components</p> </li> <li> <p>Return Value: It returns a store object that you can interact with directly</p> </li> <li>Example: <pre><code>import { createStore } from 'zustand';\n\nconst store = createStore((set) =&gt; ({\n  count: 0,\n  increment: () =&gt; set((state) =&gt; ({ count: state.count + 1 })),\n}));\n\n// Usage outside of React\nstore.getState().increment();\nconsole.log(store.getState().count); // 1\n\n// If you want to use it in React, you need to create a hook manually\nimport { useStore } from 'zustand';\n\nconst useStoreHook = () =&gt; useStore(store);\n</code></pre></li> </ul>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"frontend/Zustand/#typescript","title":"Typescript","text":"<p>For Zustand's <code>create</code> function, the state type <code>T</code> is invariant, meaning TypeScript requires an explicit type annotation to ensure type safety.</p> <p>It can't infer type from the initial state because - state updates might add new fields that are not in the initial state - partial updates may change the allowed type of certain fields</p> <p>The zustand <code>create</code> function is a generic function that also takes a function as input.  <pre><code>const useStore = create((set) =&gt; ({\n  // initial state and actions\n}));\n</code></pre></p> <p>When the type parameter is explicitly defined</p> <pre><code>const useStore = create&lt;MyStateType&gt;((set) =&gt; ({\n  // initial state and actions\n}));\n</code></pre> <p>TypeScript will get confused because it doesn\u2019t know whether <code>MyStateType</code> is the type parameter or part of the function argument.  So zustand uses currying to separate the generic type parameter from the function argument. The curried syntax looks like this:</p> <pre><code>const useStore = create&lt;MyStateType&gt;()((set) =&gt; ({\n  // initial state and actions\n}));\n</code></pre> <p>Zustand suggest using <code>combine</code> to avoid explicitly defining the type during state initialization which infers the state:</p> <pre><code>import { create } from 'zustand'\nimport { combine } from 'zustand/middleware'\n\nconst useBearStore = create(\n  combine({ bears: 0 }, (set) =&gt; ({\n    increase: (by: number) =&gt; set((state) =&gt; ({ bears: state.bears + by })),\n  })),\n)\n</code></pre> <p>Curried syntax is not used when using middleware like <code>combine</code> and <code>redux</code> that create the state i.e., define the structure/shape of the state in a way that typescript can infer it automatically.</p> <p>For more information refer to the zustand Typscript guide.</p>","tags":["React","Typescript","Frontend","Store","State Management"]},{"location":"process/How%20we%20work/","title":"How we work","text":"<p>As a team, we organize our work using a couple of tools and meetings:</p>","tags":["Process"]},{"location":"process/How%20we%20work/#our-kanban-board","title":"Our Kanban board","text":"<p>The Kanban board is the single place where we visualize and track our work as a team. It visualizes what is currently a priority, and shows what is being worked on.</p>","tags":["Process"]},{"location":"process/How%20we%20work/#overview","title":"Overview","text":"<p>The board is organized from left to right:</p> <ul> <li>Backlog: An ordered list of issues that we have committed to addressing next. Issues are ranked from top to bottom in order of their importance to our aims as a team / project.</li> <li>Specify: Whenever someone is free, we take the top issue from the Backlog and pull it into \"Specify\". Here we check that the issue specification is clear and complete. Here we also split up bigger issues into smaller sub-issues to make sure that all issues on the board have a similar size</li> </ul>","tags":["Process"]},{"location":"process/How%20we%20work/#issues","title":"Issues","text":"<p>We do most of our discussion and planning on issues. To make sure everyone has all the relevant context up top, make sure the issue description is always up to date and reflects the most recent discussion.</p> <p>When an issue is done being specified, it should have a couple of TODO checkboxes so the work required and the progress so far can be seen at a glance.</p>","tags":["Process"]},{"location":"process/How%20we%20work/#pull-requests-and-reviews","title":"Pull requests and reviews","text":"<p>Pull Requests and reviews are how we make sure the implementation meets what is in the issue spec and is correct and fits our standards. Pull Requests can take a lot of time for the reviewer, so when you open a PR, it is important that you keep the changes focused on a single problem and that you provide clear context to help with the review.</p> <p>Here are some examples of good context to provide:</p> <ul> <li>Anything to pay attention to (e.g., edge case, something not implemented, new dependency introduction for custom solution)</li> <li>Related issues</li> <li>If PR includes fixes for multiple issues, structure them somehow in the description for review</li> <li>Try to avoid comining multiple issues in a single PR</li> <li>Make sure that issue has much context as possible e.g., with comments, updating description during implementation</li> </ul>","tags":["Process"]},{"location":"process/How%20we%20work/#faq-how-should-i","title":"FAQ: How should I ...","text":"<p>While working on an issue, I found a bug. where should it go?</p> <ul> <li>create an issue for the bug in the correct repository</li> <li>apply the bug label and decide what severity the bug should have and apply the severity label</li> <li>is the bug severe (e.g. does it not have an easy workaround or is not just a nuisance)<ul> <li>yes, it is a severe bug<ul> <li>add the bug to the project </li> <li>does the bug block your currently worked on feature?<ul> <li>yes, I'm blocked by this bug<ul> <li>move your issue into \"track\" and reference the bug issue</li> <li>replace your issue with the bug and begin addressing the bug (or get help if needed)</li> </ul> </li> <li>no, I am not blocked by this bug<ul> <li>set the status of the bug to \"backlog\"</li> <li>discuss it during the next standup and advocate for where you think it should be in the priority list</li> </ul> </li> </ul> </li> </ul> </li> <li>no, it is not a severe bug<ul> <li>do not add the bug to the project</li> <li>we will periodically revisit these bugs via automation</li> </ul> </li> </ul> </li> </ul> <p>I just had an idea for something that might be useful later</p> <p>Thoughts that are not part of the current focus  and still need some further thinking to clarify can still be useful. </p> <ul> <li>make an issue in the appropriate repo</li> <li>make a detailed description so that someone with no context in 6 months still understands what you have in mind<ul> <li>if you can't (be bothered to) write a detailed enough description, then your idea isn't important enough for an issue</li> </ul> </li> <li>apply the \"feature idea\" (or similar) label to it</li> <li>do not add it to the project</li> </ul> <p>I just had and idea, and it is related to the current focus</p> <p>If your idea is related to what is currently our main focus or roadmap issue, then we need to discuss the idea quickly.</p> <ul> <li>create an issue in the correct repository</li> <li>add the issue to the project and set the status to \"backlog\"</li> <li>advocate for your issue during standup and for where you think it should go in the priority ranking</li> <li>be ready to have the team disagree with you and demote the issue to a simple feature idea</li> </ul>","tags":["Process"]},{"location":"process/How%20we%20work/#proposed-changes-to-process","title":"Proposed changes to process","text":"<p>Situation: I want to implement an organization-wide change that will improve the quality of code/process/developer life in general, e.g., create or update a specific issue template.</p> <p>Steps: Mention it during standup (or in the <code>#Neurobagel</code> channel) before making a change so that any team members who have suggestions can reach out.</p>","tags":["Process"]},{"location":"process/How%20we%20work/#daily-standup","title":"Daily standup","text":"<p>Every day at 12 pm we meet and talk.</p>","tags":["Process"]},{"location":"process/How%20we%20work/#automatic-github-processes","title":"Automatic Github processes","text":"<p>Neurobagel is built and maintained across several repositories, but our work is organized at the level of the entire organization. That means we have to synchronize issues, labels, checks, and  workflows across many repositories so they are consistent.</p>","tags":["Process"]},{"location":"process/How%20we%20work/#synchronizing-workflows","title":"Synchronizing workflows","text":"<p>Because that can get pretty repetitive and annoying, we use Github automation wherever we can to make our life easier. Github workflows that are needed in many repositories are  maintained in our neurobagel/workflows repository, specifically in the template_workflows directory. To synchronize the template workflows to our other repos, we use the <code>sync_wf</code> workflow that is unique to the workflow repo. The <code>sync_wf</code> workflow listens for changes in the template_workflows  directory and whenever one of the template workflows is edited, <code>sync_wf</code> opens a pull request against our other neurobagel repositories to copy or update the workflow there.</p> <p>The sync is a config file (containing repo names) which is read read by the <code>sync_wf</code>. To sync required workflows for a repository, the name of the repository needs to be added to the <code>repos</code> field of the relevant file in the sync config file.</p> <p>Templates can be used to propagate different values of variables to each synchronized workflow. These variables can include strings with typical GitHub variable expansion syntax if each repo's workflow needs to use a secret as part of the workflow, with the following behaviour for expansion in the generated/synchronized workflows:</p> In template Turns to i.e. <code>${{ secrets.NOQUOTE }}</code> <code>${{ secrets.NOQUOTE }}</code> stays the same <code>'${{ secrets.QUOTED }}'</code> <code>${{ secrets.QUOTED }}</code> string removed, same outcome as no quotes <code>${ secrets.SINGLECURLY }</code> <code>${ secrets.SINGLECURL }</code> stays the same <code>{{ secrets.BETAHUHN }}</code> <code>[object Object]</code> has something unfortunate happen to it during expansion in JavaScript land and gets turned into an object -&gt; effectively still benign <p>It seems that as long as there is a <code>$</code> in front of the curly braces, they stay the same after the template is applied. And if we forget the <code>$</code>, it just turns into useless stuff and breaks, but we still don't leak secrets. </p>","tags":["Process"]},{"location":"process/How%20we%20work/#synchronizing-issues-and-labels","title":"Synchronizing issues and labels","text":"<p>We also want to use consistent labels across our repositories without having to re-create them everywhere or update them manually whenever we want to change them. All labels that are common to all repositories are maintained in our planning repository.</p> <p>Whenever a label in the planning repository is added or changed, our <code>label_sync</code> workflow ensures that this change is propagated to all other repositories.</p> <p>When we create a new repository it won't have any labels yet. For this special case, we have a second workflow that can  be triggered manually here: https://github.com/neurobagel/planning/actions/workflows/manual_label_population_to_repos.yml. This workflow will take all labels in the planning repo and copy / update them to all neurobagel repositories in one go.</p> <p>Finally we also have some Github automation to make it easier to track issues across repositories.  The <code>add_iss2project</code> workflow is maintained in the workflows repository and synched with all repos from there (see above).  Whenever a new issue is opened in any of our repositories,  this workflow adds the issue to our neurobagel project.</p> <p>Note: Because we are synchronisation labels from the planning repo,  you should only create or edit labels inside of the planning repo. An exception is if you want a label to only exist in a specific repo. In this case, you should create the label in this repo,  it will not be synced or edited by the synchronisation workflow.</p>","tags":["Process"]},{"location":"process/How%20we%20work/#deleting-the-same-label-across-multiple-repos","title":"Deleting the same label across multiple repos","text":"<p>Unlike for label creation/editing, we currently do not have an automatic process to delete labels from all repos if it has been deleted in <code>neurobagel/planning</code>, as this should be approached with more caution.</p> <p>Instead, the following script can be automatically used to delete &gt;=1 labels matching a specific label name, color, and description from all Neurobagel repos.</p> <p>To use it, update the <code>LABELS_TO_DELETE</code> variable as needed.</p> <p>If the label should be deleted from only a subset of repos, replace the value of <code>REPOS</code> with a space-separated string of repository names.</p> <pre><code>#!/bin/bash\n\n# Get all the Neurobagel repos\nREPOS=$(gh repo list neurobagel --json name | jq -r '.[].name')\n\n# NOTE: the color is case-sensitive in the matching, and should not have # in front of it\nLABELS_TO_DELETE=(\n    \"labelone,c5def5,test label 1\"\n    \"labeltwo,7D939A,test label 2\"\n)\n\n# NOTE: make sure ${REPOS} doesn't have quotes around it\nfor repo in ${REPOS}; do\n    echo \"Processing repository: ${repo}...\"\n\n    for label in \"${LABELS_TO_DELETE[@]}\"; do\n        # Get the label attributes\n        IFS=\",\" read -r label_name label_color label_description &lt;&lt;&lt; \"$label\"\n\n        # Check if the label exists with the specified name, color, and description\n        # NOTE: we set the label limit -L to something pretty big to ensure all existing labels are fetched\n        gh label list -R \"neurobagel/${repo}\" -L 200 --json name,color,description | jq -e \".[] | select(.name == \\\"$label_name\\\" and .color == \\\"$label_color\\\" and .description == \\\"$label_description\\\")\" &gt;/dev/null\n\n    if [ $? -eq 0 ]; then\n            gh label delete \"$label_name\" --repo \"neurobagel/${repo}\" --yes\n        else\n            echo \"Label not found: $label_name\"\n        fi\n    done\n\n    echo -e \"Finished processing repository: ${repo}\\n\"\n done\n</code></pre>","tags":["Process"]},{"location":"process/How%20we%20work/#testing-out-github-workflows-locally-using-netkosact","title":"Testing out GitHub workflows locally using <code>netkos/act</code>","text":"<p>act allows you to locally run workflows in a repository. This is useful when you want to quickly check (see also the Limitations section below!) the behavior of a workflow you have changed, but that workflow does not run on a PR (normally, you might have to merge your changes first and then directly run the workflow on <code>main</code>, which can be a bit annoying).</p> <p>The documentation for <code>act</code> is pretty clear, and can be found in the repository README and their user guide. Their example commands are especially helpful.</p> <p><code>act</code> needs to be installed locally, and needs Docker to work. System-specific installation instructions here.</p> <p>For example, this is what I did (I don't have homebrew, so I just installed it as a bash script): <pre><code>curl -s https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash\n\n# then, move it to my /usr/bin so it's executable as a command\nsudo mv bin/act /usr/bin\n\n# remove leftover directory\nrm bin\n\n# check if it works\nact --help\n</code></pre></p> <p>A more detailed example of how to run it on a specific workflow from a repository, e.g., <code>neurobagel/bagel-cli</code>:</p> <p>We can first list which jobs and workflows are available in the repo <pre><code>cd bagel-cli\nact -l\n</code></pre></p> <p>Let's assume we want to run the job <code>auto-release</code> from the release.yaml workflow.  This job requires the <code>NB_PAT_RELEASE</code> PAT, we will also need to provide a valid PAT under this variable name for <code>act</code> to use. Here, I used my own fine-grained PAT created with the same permissions as <code>NB_PAT_RELEASE</code>, and provided it using the <code>--secret-file</code> option:</p> <p>I first created a file called <code>my.secrets</code>: <pre><code>NB_PAT_RELEASE=[my PAT value copied from GitHub]\n</code></pre></p> <p>Then, I passed it to act when calling the job: <pre><code>act -j auto-release -W .github/workflows/release.yaml --secret-file ../my.secrets\n</code></pre></p> <p>You should see a message <code>Job succeeded</code> when the job completes successfully (Note: you might still get this message even when not all steps in the job have been entirely completed - see Limitations section below).</p> <p>note: I can also provide a custom event payload to an <code>act</code> invocation: https://nektosact.com/usage/index.html?highlight=payloa#using-event-file-to-provide-complete-event-payload</p>","tags":["Process"]},{"location":"process/How%20we%20work/#limitations","title":"Limitations","text":"<p>*While <code>act</code> aims to replicate the GitHub Actions environment, certain aspects will differ when the workflows are run in your local repo.  As a result, some local adjustments might be necessary for specific jobs, while the context of other jobs may be too specific/constrained to run properly or to completion using <code>act</code>.</p> <p>For example, given that our <code>release.yaml</code> workflow is configured to run only on pushes to the <code>main</code> branch, and also relies on merging PRs with the <code>release</code> label to actually initiate the release and calculate the version bump, etc., it appears that 1) running in the workflow with <code>act</code> on a non-<code>main</code> branch does not actually initiate the release creation, and 2) even running it on <code>main</code> is not sufficient to cause a release to be published with an appropriate version number. For example, the run on <code>main</code> would end with the following: <pre><code>| \u2714  success   Calculated SEMVER bump:\n| \u2714  success   Calculated version bump: none\n| \u2139  info      No version published.\n| \u2714  success   Teardown `auto`\n[auto release/auto-release]   \u2705  Success - Main Release\n[auto release/auto-release] Cleaning up container for job auto-release\n[auto release/auto-release] \ud83c\udfc1  Job succeeded\n</code></pre> (In this case, the local run still finishes with a Success message, which is a little bit misleading!) These types of jobs likely require additional context 'mocking' to run properly that <code>act</code> may not be able to support.</p> <p>Another apparent limitation is jobs that require some kind of uploader/uploading to an external service, such as test workflows that upload coverage reports to Coveralls/Codecov.  These jobs, when run locally, seem to consistently fail at the step of uploading/posting the coverage report (regardless of repository or the coverage suite used). One possible workaround is to skip the step that posts the coverage data, following the instructions here (have not tested).</p> <p>Finally: <code>act</code> runs on specific docker images that are purposefully not complete replications of the GH workflow runner environments.  This means that some commands you have in GH actions won't exist in <code>act</code>: https://github.com/nektos/act/issues/107 You can use a more complete docker image: https://nektosact.com/usage/runners.html but note that the biggest one is 18GB!</p>","tags":["Process"]},{"location":"process/How%20we%20work/#other-important-notes","title":"Other important notes","text":"<p>NOTE 1: Based on the docs, I think you shouldn't have to specify the workflow path in addition to the job ID, but for some reason when I tried it without the <code>-W</code> flag, I got a <code>Could not find any stages to run</code> error. I think this is an open issue, https://github.com/nektos/act/issues/1993.</p> <p>NOTE 2: If passing a secrets file to the <code>act</code> command which contains <code>GITHUB_TOKEN</code>, the variable cannot be defined inside the file as follows: <code>GITHUB_TOKEN=\"$(gh auth token)\"</code> (unlike when passing the <code>GITHUB_TOKEN</code> directly using <code>-s GITHUB_TOKEN</code>), because the .secrets file does not support this kind of expansion syntax. See https://github.com/nektos/act/issues/2130#issuecomment-1859288328 and https://nektosact.com/usage/index.html?highlight=env#envsecrets-files-structure for more info.  As a work around, you can echo the value into the file instead, e.g.: <code>echo GITHUB_TOKEN=$(gh auth token) &gt;&gt; my.secrets</code></p> <p>NOTE 2: You can also try a dry-run first, e.g. <pre><code>act -j auto-release -W .github/workflows/release.yaml --secret-file ../my.secrets -n\n</code></pre> but I'm not sure how far the dry-run actually goes/how helpful this is. For example, I first tried a dry-run locally but forgot to provide the secrets file needed for <code>auto-release</code>, and still got a \"Job succeeded\" message. Then when I ran it not as a dry run, the job failed. \ud83e\udd37 So the dry-run doesn't seem to actually 'catch' all problems by default.</p>","tags":["Process"]},{"location":"process/How%20we%20work/#working-with-long-lived-development-branches","title":"Working with long-lived development branches","text":"<ul> <li> <p>Maintenance Strategy: keeping <code>develop</code> in-sync with <code>main</code> If <code>main</code> has received changes/PRs and has moved forward after <code>develop</code> was branched off and <code>develop</code> is still being worked on, <code>main</code> must be merged into <code>develop</code> immediately after any changes land in <code>main</code>, This keeps development branch up-to-date with main. the strategy is often referred to as <code>The Back-Merge</code>: checkout to <code>develop</code> branch and merge main into <code>develop</code> i.e., <code>git checkout develop &amp;&amp; git merge main</code></p> </li> <li> <p>Feature strategy: merging feature into <code>develop</code> If a PR is opened against <code>develop</code>, it should be squashed and mergeed since the two branches share history and we want to see one clear commit per feature/fix/etc e.g., feat: set up normalized store, rather than 15 commits e.g., chore: fixed typo, etc. </p> </li> <li> <p>Release strategy: merging <code>develop</code> into <code>main</code> If <code>develop</code> has accumulated the planned features and is ready for release. The changes should merged using a standard merge commit since the desired goal is to perserve the history of <code>develop</code>. The merge commit acts as a \"container\" for that release. If we need to revert the entire release, we can revert this single merge commit</p> </li> </ul>","tags":["Process"]},{"location":"process/How%20we%20work/#daisy-chaining-pull-requests","title":"Daisy chaining pull requests","text":"<p>When addressing multiple issues of the same repository in succession, it's better to not branch off of the feature branch with the latest changes as it may lead to conflicts that if not handled properly may overwrite some of the changes made. For a safer approach, branch off of main for each issue.</p>","tags":["Process"]},{"location":"process/Neurobagel%20Code%20of%20Conduct/","title":"Neurobagel code of conduct","text":"","tags":["Process","Internal Documentation"]},{"location":"process/Neurobagel%20Code%20of%20Conduct/#code-of-conduct","title":"Code of Conduct","text":"<p>In the interest of fostering an open and welcoming environment we want participation in our project and our community to be a harassment-free experience for everyone.</p> <p>Although no list can hope to be all-encompassing, we explicitly honor diversity in age, body size, disability, ethnicity, gender identity and expression, level of experience, native language, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>","tags":["Process","Internal Documentation"]},{"location":"process/Neurobagel%20Code%20of%20Conduct/#our-standards","title":"Our Standards","text":"<p>We aim to promote behavior that contributes to a positive and welcoming environment. Examples of such behavior include:</p> <ul> <li>Using inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>We do not tolerate harassment or other, inappropriate behavior in our community. Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Personal or political attacks on contributors, and insulting or derogatory   comments on contributed code with the intent to undermine contributions</li> <li>Publishing others' private information, such as a physical or electronic address,    without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> <li>Public or private harassment</li> </ul>","tags":["Process","Internal Documentation"]},{"location":"process/Neurobagel%20Code%20of%20Conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>The maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>The maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>","tags":["Process","Internal Documentation"]},{"location":"process/Neurobagel%20Code%20of%20Conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within our online GitHub repository and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>","tags":["Process","Internal Documentation"]},{"location":"process/Neurobagel%20Code%20of%20Conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting our Code of Conduct Enforcement Team: Elizabeth Dupre, Dan Handwerker, and Stefano Moia. Confidentiality will be respected in reporting. The Code of Conduct Enforcement Team any take any action they deem necessary for the safety of the <code>tedana</code> community, including but not limited to:</p> <ul> <li>facilitating a conversation between the two parties involved in the violation of the code of conduct</li> <li>requesting a contributor apologize for their behaviour</li> <li>asking a contributor or multiple contributors to enter a cooling off period that puts a   time-limited pause on a particular discussion topic</li> <li>asking a contributor to no longer participate in the development of <code>tedana</code></li> </ul> <p>For more details on the enforcement process, please see our documentation on governance.</p>","tags":["Process","Internal Documentation"]},{"location":"process/Neurobagel%20Code%20of%20Conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the tedana code of conduct which itself is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html,  and from the nipreps code of conduct.</p>","tags":["Process","Internal Documentation"]},{"location":"process/Neurobagel%20PATs/","title":"Neurobagel PATs","text":""},{"location":"process/Neurobagel%20PATs/#existing-pats","title":"Existing PATs","text":"<p>Below is a list of PATs which are used in our active workflows and should be renewed immediately when expired.</p> <p>Secret names and permissions:</p>"},{"location":"process/Neurobagel%20PATs/#neurobagel-organization","title":"Neurobagel organization","text":"<p> : user-created PAT has been replaced by the Neurobagel Bot app</p> <ul> <li> NB_PROJECT_PAT:<ul> <li>Creator: @surchs</li> <li>Purpose: we use this PAT to add new issues to the board</li> <li>Org permission: Read and Write access to organization projects</li> <li>Repo permission: Read access to metadata</li> <li>Repo permission: Read and Write access to code, issues, and pull requests</li> </ul> </li> <li> NB_PR_PAT:<ul> <li>Creator: @surchs</li> <li>Purpose: We use this PAT to discover PRs opened by bots and to move them to the board</li> <li>Org permission: -</li> <li>Repo permission: Read access to metadata</li> <li>Repo permission: Read and Write access to actions, code, issues, pull requests, and workflows</li> </ul> </li> <li> NB_PAT_RELEASE<ul> <li>Creator: @surchs</li> <li>Purpose: We use this PAT to make automatic releases with intuit/auto</li> <li>Org permission: -</li> <li>Repo permission: Read access to metadata</li> <li>Repo permission: Read and Write access to actions, code, commit statuses, deployments, issues, pull requests, repository hooks, and workflows</li> </ul> </li> <li> NB_PAT_RELEASE_PROTECTED <ul> <li>Creator: @alyssadai</li> <li>Purpose: We use this PAT to be able to automatically release on protected branches using the protected-branch plugin for intuit/auto. This requires a different PAT than <code>NB_PAT_RELEASE</code> since a CHANGELOG PR is auto-created as part of the process, but a PR author cannot approve their own PR.</li> <li>Org permission: -</li> <li>Repo permission: Read access to metadata</li> <li>Repo permission: Read and Write access to actions, code, commit statuses, deployments, issues, pull requests, repository hooks, and workflows</li> </ul> </li> <li> LAB_PAT<ul> <li>Creator: @surchs</li> <li>Purpose: We use this PAT to synchronize labels across repositories</li> <li>Org permissions: Read and Write access to organization actions variables and organization projects</li> <li>Repo permissions: Read access to metadata</li> <li>Repo permissions: Read and Write access to actions, issues, and pull requests</li> </ul> </li> <li>GH_PAT in the https://github.com/neurobagel/upptime/ repo<ul> <li>Creator: @surchs</li> <li>Purpose: We use this PAT to run the upptime workflow</li> <li>Org permissions: -</li> <li>Repo permissions: Read access to metadata</li> <li>Repo permissions: Read and Write access to actions, code, issues, and workflows</li> </ul> </li> </ul>"},{"location":"process/Neurobagel%20PATs/#openneurodatasets-jsonld-organization","title":"OpenNeuroDatasets-JSONLD organization","text":""},{"location":"process/Neurobagel%20PATs/#github-repo","title":".github repo","text":"<ul> <li>NB_OPENNEURO_ANNOTATIONS_RW<ul> <li>Creator: @alyssadai</li> <li>Purpose: Used to push updated JSONLDs to a branch in the <code>neurobagel/openneuro-annotations</code> repo</li> <li>Org permissions: -</li> <li>Repo permissions: Read access to metadata</li> <li>Repo permissions: Read and Write access to actions, code, and workflows</li> </ul> </li> <li>ON_WF_PAT<ul> <li>Creator: @surchs</li> <li>Purpose: Used to create/update forks of OpenNeuro and keep OpenNeuroDatasets-JSONLD in sync with OpenNeuroDatasets</li> <li>Permissions: Read and Write access to actions, administration, code, commit statuses, deployments, issues, pull requests, and workflows</li> </ul> </li> </ul>"},{"location":"process/Neurobagel%20PATs/#updating-the-personal-access-tokens","title":"Updating the Personal Access Tokens","text":"<p>Our GH action workflows rely on https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens. Currently they are created by individual admin users for the @neurobagel org. However, these PATs expire - e.g. after 60 days.</p> <p>To keep the lights on for our workflows, two things have to be done when PATs expire:</p> <ol> <li>Renew the PAT. If you do this while the old PAT is still valid, you can just use the \"renew\" button in the Github interface. You will also get a link to this \"renew\" button in the email from GitHub that reminds you the PAT will expire</li> <li>Copy the new PAT into the organization secrets. When you renew a PAT you  also change the PAT secret. Make sure to copy that secret before closing the tab, because you will only be able to see it once. When you have copied it, make sure to update the organization secrets here: https://github.com/neurobagel/documentation/settings/secrets/actions with the new value. Make sure you update the correct secret with the PAT that has the correct permissions. In our GH worklows we refer to the secret by name, and they need to have the right permissions.</li> </ol>"},{"location":"process/Neurobagel%20PATs/#fyi-workflows-triggered-by-a-pr-from-a-fork","title":"FYI: Workflows triggered by a PR from a fork","text":"<ul> <li>GitHub secrets (e.g., PATs) are not passed to wfs triggered from a forked repo (e.g., a PR from a fork), with the exception of <code>GITHUB_TOKEN</code></li> <li>However, when a wf is triggered by a PR from a forked repository, GitHub only grants read access tokens for <code>pull_request</code> events, at most.  So, to allow writing to the PR (e.g., adding a label), the wf trigger event needs to be changed to <code>pull_request_target</code> instead of <code>pull_request</code> (see example here).</li> <li>This works because <code>pull_request_target</code> alters the context of the action and safely (?) grants additional permissions.</li> </ul> <p>See also:  GitHub token permissions documentation</p>"},{"location":"process/Neurobagel%20PATs/#github_token-tips","title":"<code>GITHUB_TOKEN</code> tips","text":"<ul> <li>By default, <code>GITHUB_TOKEN</code> only has read access to a repo.  The top-level <code>permissions</code> key in a workflow is used to modify permissions for <code>GITHUB_TOKEN</code>.</li> <li>Alternatively, if more permissions are needed, a PAT / app installation token can also be specified in specific workflow steps. This will supersede any top-level <code>permissions</code> granted to <code>GITHUB_TOKEN</code>.</li> </ul> <p>Example: <pre><code>    step:\n      - name: My privileged step\n        with:\n          token: ${{ secrets.MY_PAT }}\n</code></pre></p> <p>See also:  GitHub token permissions documentation</p>"},{"location":"process/Neurobagel%20PATs/#authenticating-using-the-neurobagel-bot-app","title":"Authenticating using the Neurobagel Bot app","text":"<p>Neurobagel Bot app: https://github.com/organizations/neurobagel/settings/installations/52978124</p> <p>Associated org secrets and variables:</p> <ul> <li><code>NB_BOT_ID</code>: variable, app id (not client id!) for app</li> <li><code>NB_BOT_KEY</code>: secret, private key for app</li> </ul> <p>Modifying <code>NB_BOT_KEY</code> secret</p> <p>When changing the value of <code>NB_BOT_KEY</code> secret, be sure to copy all the contents of your private key including any white space.  As a best practice, make sure to include the <code>-----BEGIN RSA PRIVATE KEY-----</code> and <code>-----END RSA PRIVATE KEY-----</code> when copying the value.</p>"},{"location":"process/Neurobagel%20PATs/#permissions","title":"Permissions","text":"<p>Neurobagel Bot (<code>neurobagel-bot</code>) was created and is installed under the @neurobagel organization</p> <ul> <li>The app has been given access to all repositories in the org</li> <li>App permissions (repository level):<ul> <li>Read access to metadata</li> <li>Read and write access to actions, administration, checks, code, commit statuses, deployments, issues, projects, pull requests, variables, webhooks, and workflows</li> </ul> </li> <li>App permissions (organization level):<ul> <li>Read and write access to projects, and variables</li> </ul> </li> </ul>"},{"location":"process/Neurobagel%20PATs/#how-to-use","title":"How to use","text":"<p>The app ID and private key for the app can be used in a workflow to generate an installation access token, which allows authentication on behalf of the app  (i.e., as an app installation which has been granted access to certain repository resources with certain permissions).</p> <p>Note: The app's private key is different than the app's client secret, which is used to generate user tokens (more info: https://docs.github.com/en/enterprise-cloud@latest/apps/creating-github-apps/about-creating-github-apps/best-practices-for-creating-a-github-app#secure-your-apps-credentials).</p>"},{"location":"process/Neurobagel%20PATs/#in-a-workflow-that-acts-on-a-different-repo","title":"In a workflow that acts on a different repo","text":"<p>By default, <code>actions/create-github-app-token</code> only creates a token scoped to repo the workflow is in, even if the app itself has permissions for all repos in the organization.</p> <p>If the workflow needs to make changes to a different repo (commit, open PR, etc.), we need to explicitly specify the <code>owner</code> key to tell the action to generate a token for all repos in the owner's installation of the app.</p> <p>Without the above step, we might get an error that looks like this: <pre><code>  remote: Permission to neurobagel/neurobagel_examples.git denied to neurobagel-bot[bot].\n  fatal: unable to access 'https://github.com/neurobagel/neurobagel_examples/': The requested URL returned error: 403\n  Error: The process '/usr/bin/git' failed with exit code 128\n</code></pre></p>"},{"location":"process/Neurobagel%20PATs/#references","title":"References","text":"<p>Modifying a GitHub app: https://docs.github.com/en/enterprise-cloud@latest/apps/maintaining-github-apps/modifying-a-github-app-registration</p> <p>Full docs for authenticating with a GitHub app:</p> <ul> <li>https://docs.github.com/en/enterprise-server@3.11/apps/creating-github-apps/authenticating-with-a-github-app/making-authenticated-api-requests-with-a-github-app-in-a-github-actions-workflow</li> <li>https://docs.github.com/en/enterprise-cloud@latest/apps/creating-github-apps/authenticating-with-a-github-app/authenticating-as-a-github-app-installation</li> </ul> <p>More info on private keys, client secrets, etc.: https://docs.github.com/en/enterprise-cloud@latest/apps/creating-github-apps/about-creating-github-apps/best-practices-for-creating-a-github-app#secure-your-apps-credentials</p>"},{"location":"process/Neurobagel%20Release%20process/","title":"Neurobagel Release process","text":"<p>For all tools, our goal is to have the <code>main</code> branch releasable at all times. That means:</p> <ul> <li>all linters and static tools are passing</li> <li>all tests are passing</li> <li>all new features since last release have appropriate documentation (as part of PR)</li> <li>the build is successful</li> </ul> <p>Note: For features that take a lot of work to implement, having <code>main</code> always be releasable requires an extra step. For example a feature to \"make this experiment reproducible\" might take several PRs to implement.  To still have <code>main</code> be in a releasable state, we will have to hide the in-progress feature behind  a feature flag.</p> <p>The goal is that we could release always, but we choose to release only when it makes sense. Related: the work to do an actual release should be minimal, and only involve the actual release process:</p> <ul> <li>changelog editing</li> <li>version increment picking</li> <li>celebrating </li> </ul> <p>It should not include any fixes, changes, or the writing of new documentation.</p>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#when-to-release","title":"When to release","text":"<p>We will decide when to make a release as a team. The goal for releases is:</p> <ul> <li>Release often - A release should not be a major thing that we only do every couple of months. </li> <li>Release regularly - As much as we can, the releases should be at regular intervals. This may mean that different tools have different release intervals.</li> <li>Release when it makes sense - The idea is that we only push released versions to our deployments. So not every merged PR will get deployed. But we will want to deploy and thus release whenever we fix an important bug or a new feature.</li> </ul>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#auto-releasing-using-intuitauto","title":"Auto-releasing using <code>intuit/auto</code>","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#context","title":"Context","text":"<ul> <li>This is done using a workflow called <code>release.yaml</code> and the <code>.autorc</code> configuration file in each repo</li> <li>Note that the workflow uses PATs (not <code>GITHUB_TOKEN</code>, which doesn't have sufficient permissions) that have, among other permissions, R+W permissions to both issues and pull requests</li> </ul>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#about-pr-labels","title":"About PR labels","text":"<ul> <li><code>auto</code> uses custom labels applied to PRs in a repo to determine when a release is made, which PRs are included in the release (and under what CHANGELOG heading), and to calculate the version bump for the release (major/minor/patch)</li> <li>Each of these PR labels has one associated <code>releaseType</code> (defined in <code>.autorc</code>) that basically describes the version bump that should happen if a release were to be made containing only a PR with that label applied, and also the version bump if the label were paired with others (of potentially different <code>releaseType</code>s) on the same PR<ul> <li>Possible label <code>releaseType</code>s: \"major\", \"minor\", \"patch\", \"skip\", \"none\", \"release\" (note that these do not refer to the labels themselves, which can have different names)</li> <li>Multiple labels can have the same <code>releaseType</code></li> <li>Labels with a <code>releaseType</code> of \"major\"/\"minor\"/\"patch\" are called SEMVER labels - these are used to calculate the final version bump for a release</li> </ul> </li> </ul>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#automatically-creating-the-pr-labels-in-a-repo","title":"Automatically creating the PR labels in a repo","text":"<p>Note: as long as the label properties don't change, this step only needs to be done once in the <code>planning</code> repo, since the labels will then be propagated to all other repos via our label syncing workflow.</p> <ol> <li> <p>Install auto using binary on local machine <pre><code># replace the auto version if needed\ncurl -LJO https://github.com/intuit/auto/releases/download/v11.0.4/auto-linux.gz\n\ngunzip auto-linux.gz ~/auto\nchmod +x ~/auto\n\n# check that it works\n~/auto --help\n</code></pre></p> </li> <li> <p><code>cd</code> into the repo in which you want to create the labels <pre><code>cd neurobagel/planning\n</code></pre></p> </li> <li> <p>Ensure the <code>.autorc</code> file is available at the root of the repo</p> </li> <li> <p>Create a <code>.env</code> file in the repo root with the variable <code>GH_TOKEN</code> containing the value of a PAT with repo R+W access to at least issues and code (contents) <pre><code>GH_TOKEN=value_of_your_pat_here\n</code></pre></p> </li> <li> <p>Run <code>auto create-labels</code> from the repo root</p> </li> <li> <p>Check that the list of created labels corresponds to the ones in your <code>.autorc</code></p> </li> </ol>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#our-configuration","title":"Our configuration","text":"<p>You can find our PR label configuration here: https://github.com/neurobagel/workflows/blob/main/template_configs/.autorc The default PR label, if no labels are applied, is <code>pr-patch</code> (which also has <code>\"releaseType\": \"patch\"</code>).</p> <p>Our current <code>auto</code> configuration only releases when a PR with the <code>release</code> label applied has been merged.</p> <p>When this happens, all PRs that have been merged since the last release are collected and <code>auto</code> looks at the PR label(s) on each to figure out:   - if the PR should be included in the changelog     - if a PR has a label of <code>skip-release</code> (has <code>\"releaseType\": \"skip\"</code>) this always takes precedence over other SEMVER labels on the same PR   - if so, what changelog heading it should go under (based \"changelogTitle\" label attribute in <code>.autorc</code>)</p> <p>Finally, <code>auto</code> looks for the highest-priority <code>releaseType</code> among the included PRs based on their labels, and increments either the major, minor, or patch version accordingly.</p>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#notes-from-troubleshooting-automatic-release-workflow","title":"Notes from troubleshooting automatic release workflow","text":"<ul> <li>A non-default token (not <code>GITHUB_TOKEN</code>) needs to be used to create the actual release, otherwise the release is blocked from successfully triggering another workflow (e.g., building Docker image)</li> <li>Besides the release, the changelog needs to be updated and committed to the default branch<ul> <li>Because of our <code>main</code> branch protection rules (PR required, 1 approval required), we originally used the <code>protected-branch</code> plugin for auto, which auto-creates a PR for the changelog, and then auto-reviews it and merges it<ul> <li>This requires a separate, additional token (possibly for a different user?) than the one used to create the release, b/c a PR cannot be approved by the PR author<ul> <li>In our case, the <code>NB_PAT_RELEASE</code> and <code>NB_PAT_RELEASE_PROTECTED</code> tokens were created under different users, which worked out</li> </ul> </li> </ul> </li> </ul> </li> </ul>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#problem","title":"Problem","text":"<ul> <li>Because PRs for changelogs were now auto-approved &amp; merged immediately after creation, pre-commit CI (which always runs on every commit to a PR) would not have enough time to run checks before the PR is merged and would thus often fail on these PRs, leading to red checks on <code>main</code> = bad<ul> <li>Relevant issue: https://github.com/neurobagel/workflows/issues/87</li> <li>Here, skip keywords for pre-commit CI did not have any effect because they only work on main branch commits (this is the difference between the <code>pre-commit - pr</code> and the <code>pre-commit - push</code> checks), not PRs</li> <li>We needed a way to either push directly to the main branch (without needing to open a PR) from the wf, or force it to wait for the pre-commit CI</li> </ul> </li> <li>What didn't work<ol> <li>Configure <code>pre-commit - pr</code> as a <code>requiredStatusChecks</code> for <code>protected-branch</code> (https://www.npmjs.com/package/@auto-it/protected-branch?activeTab=readme#usage), to try and force this check before the PR is merged<ul> <li>Result: release failed: <code>requiredStatusChecks</code> relies on a token that has the <code>Checks</code> permission, which is currently not supported for user PATs (this is a known issue for fine-grained PATs) - only apps can have this permission<ul> <li>classic user PATs also don't work for this</li> </ul> </li> </ul> </li> <li>Make <code>pre-commit - pr</code> a required status check for PRs at the repo level (in branch protection settings)<ul> <li>Result: release failed: workflow would error out because required pre-commit check was still pending</li> </ul> </li> <li>Explicitly temporarily enable &amp; disable force pushes in release workflow, as described in https://github.com/intuit/auto/issues/1491#issuecomment-1610120918<ul> <li>Result: release failed, with error that PR must be opened</li> </ul> </li> <li>Creating a basic, no-code app \"Neurobagel Bot\" (<code>neurobagel-bot</code>) under the Neurobagel organization to authenticate with, to try using an app installation access token for releasing + updating the changelog, following the GH docs, and making sure it was allowed to bypass required PRs in the repo settings<ul> <li>Result: release succeeded, but changelog checks still failed<ul> <li><code>pre-commit</code> now was able to be triggered by the <code>protected-branch</code> plugin, but pre-commit CI would still run separately and would fail due to the PR being merged first</li> </ul> </li> </ul> </li> </ol> </li> <li>What worked<ul> <li>(it looks like this IS actually documented in the auto docs from this issue, and I just missed it somehow...)</li> <li>The PATs originally being used for the release wf belonged to org admins who should (theoretically) be allowed to bypass required PRs based on current rules<ul> <li>Same for the bot app, which was allowed to bypass required PRs</li> <li>So, it was strange when we removed the <code>protected-branch</code> plugin (which always creates a PR?), we were still getting the error in the wf failure that a PR was required</li> </ul> </li> <li>The culprit was that a more privileged access token needed to be given to the earlier <code>actions/checkout</code> step itself, otherwise the limited default auth level (the basic GitHub token) is used and persists in subsequent steps. This prevented more privileged git commands (e.g., pushing directly to a protected branch) from succeeding in subsequent steps, even though those steps had an appropriate token</li> <li>Refs:<ul> <li>https://github.com/marketplace/actions/checkout#checkout-v4 (maybe worth looking into <code>persist-credentials: false</code>?)</li> <li>https://stackoverflow.com/a/72515781</li> <li>https://stackoverflow.com/questions/63733822/cant-push-to-protected-branch-in-github-action</li> </ul> </li> </ul> </li> </ul>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#working-configuration","title":"Working configuration","text":"<ul> <li><code>neurobagel-bot</code> is installed in all repos</li> <li>Add <code>neurobagel-bot</code> as app allowed to bypass required PRs in repo settings<ul> <li>ensure that the app ID is stored as an actions variable, and private key as an actions secret</li> </ul> </li> <li>Remove <code>protected-branch</code> plugin from auto (so custom reviewer PAT also no longer required)</li> <li>In release.yaml, obtain &amp; use installation access token for <code>neurobagel-bot</code> in both <code>actions/checkout</code> and subsequent steps for the release creation</li> </ul> <p>Related issues: - https://github.com/neurobagel/planning/issues/64</p>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#create-a-release","title":"Create a release","text":"<ol> <li>To ensure that PRs since the last release end up under the appropriate heading in the changelog, when opening a PR, the author should always manually apply at least one PR label from our <code>.autorc</code> config (note: the <code>pr-patch</code> label is used by default behind the hood if no labels are applied, but we should aim to intentionally apply these to avoid having to modify changelog sections after a release)<ul> <li>For most changes, the author should choose the most relevant* label starting with the <code>pr-</code> prefix</li> <li>If a PR should be excluded from the changelog (e.g., some small automation PR that is not user-relevant), the 'skip-release' label should be applied</li> </ul> </li> <li>To auto-release after the PR you are working on is merged, apply the <code>release</code> label to the PR along with a relevant <code>pr-</code> prefixed label (note to double check: if no <code>pr-</code> labels are applied, the default one used should be <code>pr-patch</code>)</li> <li>To include extra release notes in the changelog, you can do so by modifying the PR description following these instructions: https://intuit.github.io/auto/docs/generated/changelog#additional-release-notes</li> <li>Once your release PR is merged, check that the release was created successfully with the expected tag + SEMVER (you can also double check that the <code>release.yaml</code> workflow in the repo succeeded), and double check the changelog</li> </ol> <p>*Each PR included in the release will be assigned to a single changelog section based upon the applied label with the highest <code>releaseType</code> that has a <code>changelogTitle</code>.  So, be careful when applying multiple <code>pr-</code> labels to the same PR - make sure that the label with the highest priority <code>releaseType</code> actually has the changelog section you want the PR to be listed under. See also https://intuit.github.io/auto/docs/configuration/autorc#changelog-titles)</p> <p>Docs: https://intuit.github.io/auto/docs</p>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#auto-pushing-to-dockerhub-wip","title":"Auto-pushing to DockerHub [WIP]","text":"<p>Once you have made a new release,  a new GH workflow will start to:</p> <ol> <li>Build a new Docker image from the tagged commit</li> <li>Ensure that the build and test succeed (if not -&gt;  -&gt;  -&gt; )</li> <li>Tag the new Docker image with two tags:<ul> <li><code>latest</code> to show that it is the latest released version</li> <li><code>&lt;version&gt;</code> to show that it is the specified version</li> </ul> </li> <li>Push the Docker image to docker hub</li> <li>(where applicable) -&gt; push the new version to production<ul> <li>this may be a manual process</li> </ul> </li> </ol> <p>If we encounter a bug or notice things failing somewhere during this process, fixing this bug becomes the top priority for everyone. The fix for the bug becomes the next release and then gets deployed. While the fix is being worked on we will deploy <code>:oldstable</code>.</p>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#how-to-release-manually-old","title":"How to release manually (OLD)","text":"<p>At any given moment, the <code>main</code> branch is in a releasable state (see above). To actually make a release, we use the normal GitHub release workflow. Specifically:</p> <ol> <li>Click the \"new Release\" button</li> <li>Add a new \"tag\"<ul> <li>the tag has to follow semantic versioning: https://semver.org/ (see below)</li> <li>check out the changelog (see below) to decide whether to make a patch, minor, or major version increase</li> </ul> </li> <li>Add a title. The title has to match the \"tag\"<ul> <li>i.e. for a new release called <code>\"v0.2.4\"</code> the Release title would also be <code>\"v0.2.4\"</code></li> </ul> </li> <li>Use the \"generate release notes\" button to add the <code>git log</code> since the last release<ul> <li>This also adds a section about new contributors!</li> </ul> </li> <li>Edit the changelog (see also the Example release notes template)<ul> <li>for minor and major versions (optional for patches) add a short description of the release on top of the changelog</li> <li>e.g. \"This release introduces new functionality for EEG data\" or \"This release introduces a breaking change in the XYZ workflow ...\"</li> <li>sort the changelog by type of change (i.e. a section with all of the <code>[FIX]</code> changes, one for all the <code>[FEAT]</code>, and so on)</li> <li>remove irrelevant changes (e.g. dependabot version bumps?)</li> </ul> </li> <li>Store the release as a draft</li> <li>Discuss the ready-to-go release during standup<ul> <li>gives folks a chance to take a last look</li> <li>possibility for feedback on the release notes</li> </ul> </li> <li>Release if no objections  </li> </ol>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#example-release-notes-template-old","title":"Example release notes template (OLD)","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#summary","title":"Summary","text":"<p>This release introduces X. This release includes a breaking change to Y.</p>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#whats-changed","title":"What's Changed","text":"<p>(Aim to group changes of the same type/prefix)</p>","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#new-or-improved-features","title":"New or improved features \u2728","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#changes-to-the-data-model-for-inputsoutputs","title":"Changes to the data model for inputs/outputs","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#documentation-updates","title":"Documentation updates \ud83d\udcdc","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#bug-fixes","title":"Bug fixes \ud83d\udee0\ufe0f","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#other-changes","title":"Other changes \ud83e\uddf9","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#other-important-notes","title":"Other important notes","text":"","tags":["Process","Deployment"]},{"location":"process/Neurobagel%20Release%20process/#commiting-after-release-was-triggered","title":"Commiting after release was triggered","text":"<p>If a commit is added to the <code>main</code> branch (or whichever branch is configured to release off of) after the release workflow was triggered and before it finishes, auto will create the tag for the release but it will error out and won't finalize the release to avoid collisions. See this query tool issue for more details.</p>","tags":["Process","Deployment"]},{"location":"testing/Cypress%20Snippets/","title":"Cypress Snippets","text":"","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#cypress-unit-testing","title":"Cypress unit testing","text":"<p>Aside from browser-based testing, cypress is also just a neat test runner for other JS testing libraries.  So we can use it to run unit tests.  This is useful for testing store methods like getters and mutations that don't have any UI elements.</p> <p>All of the information below is taken from this very cool blog post: https://dev.to/bahmutov/unit-testing-vuex-data-store-using-cypress-io-test-runner-3g4n The vuex testing docs are also good: https://vuex.vuejs.org/guide/testing.html and because cypress is just the test runner, we can use the syntax of the tests from there directly as well.</p>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#unit-test-a-store-mutation","title":"Unit test a store mutation","text":"<p>If our mutation is called <code>increment</code> like so:</p> <pre><code>export const mutations = {\n  increment(state) {\n    ...\n  },\n}\n</code></pre> <pre><code>import { mutations } from '../../src/counter'\n\ndescribe('mutations', () =&gt; {\n  context('increment', () =&gt; {\n    const { increment } = mutations\n    it('INCREMENT', () =&gt; {\n      const state = { count: 0 }\n      increment(state)\n      // see https://on.cypress.io/assertions\n      // for \"expect\" examples\n      expect(state.count).to.equal(1)\n    })\n  })\n})\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#unit-test-a-store-getter","title":"Unit test a store getter","text":"<p>If we have defined a store getter like so <pre><code>export const getters = {\n  myGetter (state, someArg ) {\n    return state.someVariable.filter(value =&gt; \"someLogic\")\n  }\n}\n</code></pre></p> <p>Then we can test the getter like so:</p> <pre><code>import { getters } from './getters'\n\ndescribe('getters', () =&gt; {\n  it('filteredProducts', () =&gt; {\n    // mock state\n    const state = {\n      someVariable: [\n        { id: 1, title: 'Apple', category: 'fruit' },\n        { id: 2, title: 'Orange', category: 'fruit' },\n        { id: 3, title: 'Carrot', category: 'vegetable' }\n      ]\n    }\n    // mock getter\n    const filterCategory = 'fruit'\n\n    // get the result from the getter\n    const result = getters.filteredProducts(state, { filterCategory })\n\n    // assert the result\n    expect(result).to.deep.equal([\n      { id: 1, title: 'Apple', category: 'fruit' },\n      { id: 2, title: 'Orange', category: 'fruit' }\n    ])\n  })\n})\n</code></pre> <p>See also: https://vuex.vuejs.org/guide/testing.html#testing-getters</p>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#cypress-component-test-snippets","title":"Cypress Component test snippets","text":"<p>Cypress mounts the component using the vue-test-utils library. That means, even if the Cypress documentation doesn't say so, you can use anything that the <code>vue-test-utils</code> documentation has enabled. </p> <p>For example, Cypress doesn't tell you how to write <code>listeners</code> for events emitted by your component, but you can look up in the  vue-test-utils docs how to do it.</p> <p>Also take a look at: - the Cypress component test docs (somewhat incomplete) - vue-test-utils mount docs (Recall that Cypress has a slightly different syntax for assertions, using the <code>cy.xyz()</code> commands.) - the Vue testing handbook (This has some nice patterns, but is not specifically for Cypress.)</p> <p>Also note that we are using Vue2 (specifically Nuxt2) and that many docs now start assuming that you use Vue3 (and thus different store libraries, component APIs, test library version, etc). So sometimes examples may be written for Vue3 and not work for us on Vue2.</p>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#pass-info-into-the-component","title":"Pass Info Into the Component","text":"<p>When a component relies on information being passed to it by other parts of the app, then we need to: 1. Simulate (\"mock\") this information when the component is tested in isolation during a component test.  2. Pass the simulated information to the component in a way that  looks as if it came from the expected source.</p> <p>Components in Vue can receive information in a number of different ways: - as props - via <code>provide</code> / <code>inject</code> - from a global store - ...</p> <p>Below are examples for how you can mock each of these and pass them to the  component during a component test.</p>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#import-a-component","title":"Import a Component","text":"<pre><code>import ComponentName from \"~/components/component-name.vue\";\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#pass-a-prop","title":"Pass a Prop","text":"<pre><code>cy.mount(ComponentName, {  \n    propsData: {\n        myProp: \"hasSomeValue\"\n    }\n});\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#import-plugins","title":"Import Plugins","text":"<pre><code>cy.mount(ComponentName, {\n    plugins: [\"bootstrap-vue\", \"vue-select\"]\n});\n\n#### Pass a Vuex Getter\n```javascript\ncy.mount(ComponentName, {  \n    computed: {\n        myGetter: () =&gt; {\n            return \"myGetterValue\";\n        }\n    }\n});\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#pass-a-vuex-getter-that-takes-an-argument-or-simulating-a-mapgetters-field","title":"Pass a Vuex Getter that Takes an Argument (or Simulating a mapGetters Field)","text":"<pre><code>cy.mount(ComponentName, {  \n    computed: {\n        myGetter: () =&gt; (myGetterArgument) {\n            const myReturnValue = doSomethingWith(myGetterArgument);\n            return myReturnValue;\n        }\n    }\n);\n</code></pre> <p>Note: It is usually better to completely mock the return value of  a getter rather than trying to import the getter from the store. This is for three reasons:</p> <ol> <li>Getters in Vuex take iterative inputs (see e.g. here) in the store and unit tests (see here) but when we use them in components they behave like regular functions (see here).  If we import a getter during non-e2e testing (i.e. when the app is not running), we would first have to turn the getter into a regular function ourselves by passing an also mocked store object to it.</li> <li>Getter can have other getters as dependencies.  Not only will all of these getters have to be made into normal functions as well, but so do their dependencies in turn, and so on. Additionally all of these getters depend on different parts of the  store to be mocked, so we can quickly approach a situation where we are almost mocking the entire app at runtime, just to make a  component test \"easier\".</li> <li>Importing getters is less readable than just showing what information the mocked getter will give to the component. This is maybe the most important reason, because readability is key for our tests.</li> </ol> <p>In short: mock getters as simple return objects everywhere. The only exception is when you are unit-testing the getter itself.</p>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#pass-a-vuex-state-field-or-simulating-a-mapstate-field","title":"Pass a Vuex State Field (or Simulating a mapState Field)","text":"<pre><code>cy.mount(ComponentName, {  \n    mocks: {\n        $store: {\n            state: { myStateField: \"myStateValue\" }\n        }\n    }\n});\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#mock-a-zustand-store-inside-a-react-component-test","title":"Mock a Zustand store inside a React component test","text":"<p>Some of our React component tests rely on Zustand stores for their data. You can manipulate the store directly from Cypress by calling the store's <code>setState</code> inside a <code>cy.then</code>, which guarantees the state change runs in sequence with the Cypress command queue.</p> <pre><code>import { useFreshDataStore } from \"~/stores/useFreshDataStore\";\n\nit(\"should show unavailable message when selected column data is missing\", () =&gt; {\n  cy.mount(&lt;ValueAnnotation /&gt;);\n  cy.get('[data-cy=\"side-column-nav-bar-unannotated\"]').click();\n  cy.get('[data-cy=\"side-column-nav-bar-other-select-button\"]').click();\n\n  cy.then(() =&gt; {\n    useFreshDataStore.setState((state) =&gt; {\n      const updatedColumns = { ...state.columns };\n      delete updatedColumns[\"6\"];\n\n      return {\n        ...state,\n        columns: updatedColumns,\n      };\n    });\n  });\n\n  cy.get('[data-cy=\"column-data-unavailable\"]')\n    .should(\"be.visible\")\n    .and(\"contain\", \"Selected column data is unavailable.\");\n});\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#respond-to-information-coming-out-of-the-component","title":"Respond to information coming out of the component","text":"<p>Components may have to send information to other parts of the app when certain events occur or conditions are met. When the component is tested in isolation during a component test, these other parts of the app don't exist. However, during a component test we only care about the component. So the only thing we need to test is that the component emits the right type of information in the right situations. We don't have to simuate other parts and how they would respond to  this information (this is done during full integration tests instead). </p> <p>As with passing data to components, there are different ways data can come out of components:</p> <ul> <li>emitted events</li> <li>store mutations and actions</li> </ul> <p>Below are some snippets for how you can listen to these types of data flows in a component test.</p>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#listen-to-a-vuex-state-mutation-being-committed","title":"Listen to a Vuex State Mutation Being Committed","text":"<p><pre><code>const mockStore = {  \n    commit: () =&gt; { }  \n};  \ncy.spy(mockStore, \"commit\").as(\"commitSpy\");\n\ncy.mount(ComponentName, {  \n    mocks: {  \n        $store: mockStore  \n    }\n});\n\ncy.get(\"something\").click(); // Or, do something to evoke the mutation\ncy.get(\"@commitSpy\").should(\"have.been.calledOnce\");\n</code></pre> You can chain assertions off of <code>should</code>, see the docs.</p>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#listen-to-a-vuex-state-action-being-dispatched","title":"Listen to a Vuex State Action Being Dispatched","text":"<pre><code>const mockStore = {  \n    dispatch: () =&gt; { }  \n};  \ncy.spy(mockStore, \"dispatch\").as(\"dispatchSpy\");\n\ncy.mount(ComponentName, {  \n    mocks: {  \n        $store: mockStore  \n    }\n});\n\ncy.get(\"something\").click(); // Or, do something to evoke the mutation\ncy.get(\"@commitSpy\").should(\"have.been.calledOnce\");\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#check-that-a-specific-payload-was-sent-with-the-mutation-action","title":"Check that a Specific Payload was Sent with the Mutation / Action","text":"<pre><code>const mockStore = {  \n    commit: () =&gt; { }  \n};  \ncy.spy(mockStore, \"commit\").as(\"commitSpy\");\n\ncy.mount(ComponentName, {  \n    mocks: {  \n        $store: mockStore  \n    }\n});\n\ncy.get(\"something\").click(); // Or, do something to evoke the mutation\ncy.get(\"@commitSpy\").should(\"have.been.calledWith\", \"myMutationName\", {\n    payloadField: \"payLoadValue\"});\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#listen-for-an-emitted-event","title":"Listen for an emitted event","text":"<pre><code>const mySpy = cy.spy().as(\"mySpy\");\ncy.mount(ComponentName, {\n    listeners: {\n        emitEventName: mySpy,\n    }\n});\n\n// Perform an interaction to evoke the emit\ncy.get(`.&lt;class-name&gt;`).click();\n\n// Check to see if emit was called\ncy.get(\"@mySpy\").should(\"have.been.called\");\n\n// Something to note is that 'emitEventName' must maintain the type of case used by the component (i.e. kebab-case, or camel case)\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#check-an-emitted-events-payload","title":"Check an emitted event's payload","text":"<pre><code>const mySpy = cy.spy().as(\"mySpy\");\ncy.mount(ComponentName, {\n    listeners: {\n        emitEventName: mySpy,\n    }\n});\n\n// Perform an interaction to evoke the emit\ncy.get(`.&lt;class-name&gt;`).click();\n\n// Check to see if emit was called with the correct payload\ncy.get(\"@mySpy\").should(\"have.been.calledWith\", {\n    payloadField: \"payLoadValue\"\n});\n\n// Something to note is that 'emitEventName' must maintain the type of case used by the component (i.e. kebab-case, or camel case)\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#listen-for-a-method-call","title":"Listen for a method call","text":"<pre><code>cy.spy(ComponentName.methods, 'methodName').as(\"mySpy\");\ncy.mount(ComponentName);\n\n// Perform an interaction to evoke the method\ncy.get(`.&lt;class-name&gt;`).click();\n\n// Check to see if method was called\ncy.get(\"@mySpy\").should(\"have.been.called\");\n\n// Something to note is that 'methodName' must maintain the type of case used by the component (i.e. kebab-case, or camel case)\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#check-a-method-calls-payload","title":"Check a method call's payload","text":"<pre><code>// Given methodName(value-1, value-2)\n\ncy.spy(ComponentName.methods, 'methodName').as(\"mySpy\");\ncy.mount(ComponentName);\n\n// Perform an interaction to evoke the method\ncy.get(`.&lt;class-name&gt;`).click();\n\n// Check to see if method was called\ncy.get(\"@mySpy\").should(\"have.been.called\", \"value-1\", \"value-2\");\n\n// Something to note is that 'methodName' must maintain the type of case used by the component (i.e. kebab-case, or camel case)\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#provide-different-responses-based-on-a-condition-when-intercepting-requests","title":"Provide different responses based on a condition when intercepting requests","text":"<p>The following snippet is from <code>Checkbox.cy.js</code> in the query tool. When the <code>submitQuery</code> button is clicked for the first time the condition <code>isFirstClick</code> is set to false and <code>response</code> is replied by <code>cy.intercept</code> and thereafter every click of the <code>submitQuery</code> button will result in <code>response2</code> being replied.</p> <pre><code>let isFirstClick = true;\n\ncy.intercept('GET', 'query/*', (req) =&gt; {\n  if (isFirstClick) {\n    isFirstClick = false;\n    req.reply(response);\n  } else {\n    req.reply(response2);\n  }\n});\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#miscellaneous","title":"Miscellaneous","text":"","tags":["moved"]},{"location":"testing/Cypress%20Snippets/#stubbing-a-function-from-an-external-dependency","title":"Stubbing a function from an external dependency","text":"<p>Context: In the code we're using compile method Ajv library to validate a data dictionary against a schema. In order to mock an invalid result from the validation we:</p> <ul> <li>create a stub function to replace the validation function returned by <code>Ajv.prototype.compile</code></li> <li>add mock validation errors to the <code>errors</code> property of the stub function</li> <li>stub the <code>Ajv.prototype</code> to replace <code>compile</code> with our stub function created earlier</li> </ul> <pre><code>const validateStub = cy.stub().returns(false) as ValidateFunction;\n\nvalidateStub.errors = [{ instancePath: '/column1' }, { instancePath: '/column2' }];\n\ncy.stub(Ajv.prototype, 'compile').callsFake(() =&gt; validateStub);\n</code></pre>","tags":["moved"]},{"location":"testing/Cypress%20Tasks/","title":"Cypress Tasks","text":"","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Tasks/#description","title":"Description","text":"<p>We can call upon the Cypress function <code>cy.task</code> when wanting to execute NodeJS code from within the Cypress testing context. The first use case for this in Neurobagel was for https://github.com/neurobagel/annotation_tool/pull/433 where it was necessary to read the contents of the Cypress downloads folder.</p> <p>Cypress documentation describes this function as such:</p> <p>an escape hatch for running arbitrary Node code, so you can take actions necessary for your tests outside of the scope of Cypress.</p>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Tasks/#examples","title":"Examples","text":"<p>Cypress gives a number of example scenarios where this might be useful including</p> <ul> <li>Returning the number of files in a folder</li> <li>Seeding a test database</li> <li>Storing a state in node that you want to persist between spec (Cypress test) files</li> <li>Saving a variable across URL visits with different origins</li> <li>Performing parallel tasks outside of Cypress</li> <li>Running external processes</li> </ul>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Tasks/#setup-and-use","title":"Setup and Use","text":"<p>Typical setup of a Cypress task occurs in the <code>cypress.config.js</code> that sits at the root of the app folder. In the <code>defineConfig</code> section under the key for <code>e2e</code> or <code>component</code> testing there is a <code>setupNodeEvents</code> function inside of which is a call to the Cypress <code>on</code> function. (See below.) Inside the second parameter of <code>on</code> is where it possible define different tasks you would like to call upon during testing.</p> <pre><code>const nodelib = require(\"nodelib\");\n\nmodule.exports = defineConfig({\n\n    // setupNodeEvents can be defined in either the e2e or component configuration\n    e2e: {\n\n        setupNodeEvents(on, config) {\n\n            on(\"task\", {\n\n                exampleTask(argument) {\n                    return nodelib.functionName(argument);\n                },\n\n                // More task definitions (and other external function definitions) here...\n            });\n        },\n    },\n    ...\n});\n</code></pre> <p>This task can then be used in Cypress testing as follows:</p> <pre><code>cy.task(\"exampleTask\", \"argumentValue\").then(taskReturnValue =&gt; {\n\n    // Perform more Cypress testing calls here once the task has been performed and its result returned\n});\n</code></pre>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/","title":"Cypress Vue Testing","text":"","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#setting-up-and-running-the-testing-environment","title":"Setting Up and Running the Testing Environment","text":"<ol> <li>Clone the repo you wish to test to your machine via <code>git clone &lt;repo github url&gt;</code></li> <li>Install package and developer dependencies via <code>npm install</code> in the local cloned folder</li> <li>In the terminal, start up the package locally using command <code>npm run dev</code></li> <li>In another terminal, open the Cypress interface using command  <code>npm run cypress:open</code></li> <li>In the Cypress interface, choose testing type you wish to do: \u2018end to end\u2019 or \u2018component\u2019, and choose your desired web browser to begin testing</li> <li>Tests can be done via the Cypress interface on your machine, but they will also be automatically run each time there is a new commit to the repo on Github. This is triggered via a Github Action configuration file at <code>.github/main.yml</code>.</li> <li>Both Cypress\u2019 local interface and sections in the Github interface will feature green check marks when tests have completed successfully</li> </ol>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#a-note-on-contributing-tests-for-the-neurobagel-annotation-tool","title":"A Note on Contributing Tests for the Neurobagel Annotation Tool","text":"<p>Our Nuxt-based annotation tool uses the Cypress JavaScript testing framework for end to end and component testing. While Cypress is an easy to use testing framework built upon past precedents and technologies like MochaJS, below are a few of our project-specific recommendations and guidelines for the creation of tests during feature development, enhancements, and bug fixes. This information was accrued in two ways: reading Cypress\u2019 documentation and codebase and firsthand experience with the framework guiding what works best for the app we have designed.</p>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#how-to-write-a-test","title":"How to Write a Test","text":"<ol> <li>Determine what kind of test you're writing: end to end or component</li> <li>If creating a brand new set of tests, create a js file in the appropriate folder using the <code>.cy.js</code> file extension</li> <li>Create <code>describe</code>, <code>context</code>, and <code>it</code> functions.</li> <li><code>describe</code> is a container function mostly used to the describe the suite of tests in the file</li> <li><code>context</code> is a container function used to group different kinds of tests within the file and also is used to describe that context</li> <li><code>it</code> defines the individual, specific test you are writing</li> <li>Both <code>describe</code> and <code>context</code> can contain <code>beforeEach</code> functions that will be run before every <code>context</code> or before every <code>it</code>, respectively</li> <li>Use the <code>appSetup</code> function in your <code>beforeEach</code> for the <code>describe</code> function. This calls a set of common app configuration commands.</li> <li>Writing individual tests</li> <li>Tests contain three primary sections: setup, action, and assert. They can be repeated as needed depending on the complexity of the test. But a good guideline to follow is to keep tests as simple as possible.</li> <li>It is possible to work with multiple datasets for one test file. The paradigm that has been setup can be seen, for example, in <code>annotation-pagetests.cy.js</code>. The idea is that you utilize json files in the <code>fixtures</code> folder that describe each dataset and can use functions <code>datasetMeetsTestCriteria</code> and <code>loadAppState</code> to reflect both the data needs of your test and the dataset that's being used for the test.</li> </ol>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#further-tips","title":"Further Tips","text":"","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#when-to-use-cyget-and-if-we-can-rely-on-the-dom-state","title":"When to use <code>cy.get</code> and if we can rely on the DOM state","text":"<p>Since we are using the server-side rendering version of Vue/Nuxt, it is acceptable to check the DOM for state. (In a client-side rendered app, it would not be.) Therefore we can utilize <code>cy.get</code> and its corresponding timeout time to watch for the appearance of objects on the page. However, there are other means for checking the app state. This includes checking the annotation tool Vuex store and can be done via the <code>getNuxtStoreValue</code> command.</p>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#making-testing-tests-easier","title":"Making testing tests easier","text":"<p>Cypress also includes functionality to aid test writers iteratively develop tests and run select groups of tests in sequence.</p> <p>.only and  .skip</p> <p>This Cypress syntax allows test writers to 'only' run certain tests in a file and 'skip' others. This syntax is added directly after the <code>it</code> function name. To only run one individual test in a file, you would write <code>it.only(...</code></p>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#notable-files-functions-and-variables","title":"Notable files, functions, and variables","text":"<p>$nuxt</p> <p>This variable is a direct reference to the Nuxt object. Though it should be used sparingly, this gives us direct access to the Vuex store that the annotation uses \u2013 and all of its actions and getters. </p> <p>support/commands.js</p> <p>This file contains functions that are linked to the Cypress object. The idea is to place highly reused functionality here. Any function defined here using the <code>Cypress.Commands</code> syntax may be invoked within a test function via <code>cy.</code></p> <p>assertButtonStatus</p> <p>Checks to see if a button with given data-cy attribute is enabled or disabled</p> <p>assertNextPageAccess</p> <p>Since each page in the annotation tool uses a standard naming convention for the nav and next page buttons, this function is a quick means of determining of the page's requirements for proceeeding to the next one have been met.</p> <p>datasetMeetsTestCriteria</p> <p>This function takes an object specifying page-specific criteria for a test and compares it to the config json of the dataset being used (also passed in).</p> <p>dispatchToNuxtStore and getNuxtStoreValue</p> <p>These functions are quick means of getting access to the Vuex store, either for calling actions or getting values via getters. This is possible because of Cypress' access to the <code>$nuxt</code> object.</p> <p>loadAppState</p> <p>This function gets the Vuex store state to where it needs to be for a particular page. It sets up the store with desired test criteria based on the current dataset being used.</p>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#end-to-end-testing","title":"End to End Testing","text":"","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#organization","title":"Organization","text":"<p>End to end (e2e) tests are split between two folders: <code>app</code> and <code>page</code>. The <code>app</code> folder is where full and semi-e2e test files should be placed. A 'full' e2e test moves from the home page to the download page while a <code>semi-</code> e2e test may start with any page and end with any page. The idea here is to test functionality on one page, navigate through its interface, and test its output(s) on subsequent pages. The <code>page</code> folder is where page-specific tests should be placed. These are tests that are more focused on testing all of the components on a page and their interactions. For the purpose of these tests, the state of the app needed to begin testing the page is loaded programmatically (See <code>loadAppState</code> below for description.)</p>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#component-testing","title":"Component Testing","text":"<p>In contrast to end to end testing in Cypress, component testing requires a slightly different mindset. Below are some important things to keep in mind when creating a component for testing and when setting up the actual test itself.</p>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#component-creation-and-test-creation","title":"Component creation and test creation","text":"<ol> <li> <p>Creating a brand new component with component testing already in mind gives us the advantage of simplifying what will eventually be a more complex system of components interacting within a larger web app.</p> </li> <li> <p>As such, begin creating a component with clear input and output data in mind. What are the conditions which the component needs to successfully set itself up? What is considered passable output data?</p> </li> <li> <p>During the development of our apps we have discovered that it is best to decouple a component from calls to the store almost entirely, and that it's better to emit output data back up to a more central parent component or page. This helps us for component testing as 1) the Vuex store is not initially available and 2) it negates the need to set it up for the component test.</p> </li> <li> <p>Overall, the notion of component testing itself is to simplify testing and reduce the brittleness of the overall app. The idea is that if each component of an app can successfully handle inputs and correctly satisfy its output conditions then the app itself will be less prone to errors when new features or new input data are introduced.</p> </li> </ol>","tags":["Tests","Internal Documentation","Frontend"]},{"location":"testing/Cypress%20Vue%20Testing/#component-test-setup","title":"Component test setup","text":"<ol> <li> <p>End to end tests are a fully-fleshed out piece of the Cypress testing suite. They recreate the environment in which your app sets itself up and begins. However, component tests have a much more stripped down setup functionality. This can be seen by looking at what is available in the 'this' object during a test. The Vuex <code>store</code>, for instance, is not present. This results in the need to produce several pieces of input for component creation.</p> </li> <li> <p>The value of props must be added during the mounting of a component. They are included in the second argument of the <code>cy.mount</code> command as a <code>propsData</code> key in an object. (In Vue3, this is simply <code>props</code> instead.)</p> </li> <li> <p>The value of injects must also be added during the mounting of a component. This is different than props values however because injects are essentially considered a 'global' variable. Keep in mind that the reason we sometimes use injects in our code is to avoid overly-cluttered passing props down to children and/or back up to parents. Since component testing is still in beta, it appears the best way to add inject variables is through the <code>mixins</code> property of that same second argument in which we pass <code>propsData</code>. What we are doing is acting as if data regularly injected into the component is instead a local data variable. (This pseudo-injection can be seen in <code>https://github.com/cypress-io/cypress/blob/master/npm/vue2/src/index.ts</code> where <code>installMixins</code> is called alongside a few other setup functions are called for filters, plugins, and global components.)</p> </li> <li> <p>There is a difference, however, in where we place inject data vs methods. This makes sense when we think of the mixin for injects as something that will be merged into the component object definition. For data we create a <code>data: function() { return { key: value } }</code> similar to how we would when creating a Vue component (minus the fancier <code>data()</code> syntax). And for methods we add a method within the <code>methods: { }</code> component property.</p> </li> <li> <p>Required plugins must also be listed when mounting a component. They are simply included as a list of strings in the <code>plugins</code> property of the second argument of the <code>cy.mount</code> command. If you are unsure which to add, take a look at the <code>plugins</code> property in <code>nuxt.config.js</code>. Just include the name of the plugin. There is no need to add the prefix <code>@/plugins/</code> as Cypress knows where to look for plugin code.</p> </li> </ol>","tags":["Tests","Internal Documentation","Frontend"]}]}